config:
  batch_size: 512
  cider_path: null
  data_root: ./datasets/VQAv2_arrows/
  datasets:
  - vqa
  decay_power: 1
  draw_false_image: 0
  draw_false_text: 0
  drop_rate: 0.1
  end_lr: 0
  exp_name: intra_modality_vqa
  fast_dev_run: false
  get_recall_metric: false
  get_recall_metric_itc: true
  hidden_size: 768
  image_only: false
  image_size: 576
  input_image_embed_size: 1024
  input_text_embed_size: 768
  itc_pooler: true
  learning_rate: 0.0001
  load_path: fiber_pretrain.ckpt
  log_dir: ./vqa_intra_modality/
  loss_names:
    caption_cider: 0
    caption_gold: 0
    caption_mle: 0
    itc: 0
    itm: 0
    mlm: 0
    nlvr2: 0
    vqa: 1
  lr_mult_cross_modal: 5
  lr_mult_head: 50
  max_epoch: 100
  max_steps: null
  max_text_len: 50
  mlm_prob: 0.15
  mlp_ratio: 4
  num_fuse_block: 6
  num_gpus: 4
  num_heads: 12
  num_layers: 12
  num_nodes: 1
  num_workers: 8
  optim_type: adamw
  per_gpu_batchsize: 16
  precision: 32
  pretrained_vit: false
  resolution_before: 384
  resume_from: null
  seed: 3
  test_only: false
  tokenizer: roberta-base
  train_transform_keys:
  - albef_randaug
  val_check_interval: 1.0
  val_transform_keys:
  - albef
  vit: swin_base_patch4_window12_384_in22k
  vocab_size: 50265
  vqav2_label_size: 3129
  warmup_steps: 0.1
  weight_decay: 0.01
  whole_word_masking: false
