/scratch/mjd9571/multimodal_learning/vqa_nlvr
# conda environments: # base /ext3/miniconda3 cambrian /scratch/mjd9571/conda/envs_dirs/cambrian juypter /scratch/mjd9571/conda/envs_dirs/juypter multimodal_env README.md VQAv2_arrows.zip conda_requirements.txt datasets dummy.out dummy.sbatch dummy_test.py fiber fiber_pretrain.ckpt inter_and_intra_modality nlvr-error.txt nlvr.out nlvr_image_unimodal nlvr_image_unimodal-error.txt nlvr_image_unimodal.out nlvr_image_unimodal.sbatch nlvr_image_unimodal.sh nlvr_inter-error.txt nlvr_inter.out nlvr_inter.sbatch nlvr_inter.sh nlvr_inter_modality nlvr_text_unimodal nlvr_text_unimodal-error.txt nlvr_text_unimodal.out nlvr_text_unimodal.sbatch nlvr_text_unimodal.sh old-files pip_requirements.txt run.py size_test.py slurm-49048564.out slurm-51121338.out slurm-51121339.out slurm-51121341.out slurm-51368852.out slurm-51368854.out srun-test.sbatch test.sh test_nlvr.sh vqa_image_unimodal vqa_image_unimodal-error.txt vqa_image_unimodal.out vqa_image_unimodal.sbatch vqa_image_unimodal.sh vqa_image_unimodal.txt vqa_image_unimodal_run.py vqa_image_unimodal_test-error.txt vqa_image_unimodal_test.out vqa_inter.out vqa_inter.sbatch vqa_inter.sh vqa_inter.txt vqa_inter_intra-error.txt vqa_inter_intra.out vqa_inter_intra.sbatch vqa_inter_intra.sh vqa_inter_intra_modality vqa_inter_intra_run.py vqa_inter_intra_test-error.txt vqa_inter_intra_test.out vqa_inter_modality vqa_inter_run.py vqa_inter_test-error.txt vqa_inter_test.out vqa_intra-error.txt vqa_intra-error_test.txt vqa_intra.out vqa_intra.sbatch vqa_intra.sh vqa_intra_run.py vqa_intra_test.out vqa_text_unimodal vqa_text_unimodal-error.txt vqa_text_unimodal.out vqa_text_unimodal.sbatch vqa_text_unimodal.sh vqa_text_unimodal.txt vqa_text_unimodal_run.py vqa_text_unimodal_test-error.txt vqa_text_unimodal_test.out vqainter.out vqainter.txt wandb /scratch/mjd9571/conda/envs_dirs/multimodal_env test /scratch/mjd9571/conda/envs_dirs/test
Thu Oct  3 15:44:53 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Quadro RTX 8000                On  | 00000000:06:00.0 Off |                    0 |
| N/A   56C    P8              17W / 250W |      0MiB / 46080MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Quadro RTX 8000                On  | 00000000:2F:00.0 Off |                    0 |
| N/A   54C    P8              30W / 250W |      0MiB / 46080MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  Quadro RTX 8000                On  | 00000000:86:00.0 Off |                    0 |
| N/A   40C    P8              26W / 250W |      0MiB / 46080MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  Quadro RTX 8000                On  | 00000000:D8:00.0 Off |                    0 |
| N/A   36C    P8              14W / 250W |      0MiB / 46080MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
image_state_dict.keys(): odict_keys(['cross_modal_text_transform.weight', 'cross_modal_text_transform.bias', 'cross_modal_image_transform.weight', 'cross_modal_image_transform.bias', 'cross_modal_text_transform_itc.weight', 'cross_modal_text_transform_itc.bias', 'cross_modal_image_transform_itc.weight', 'cross_modal_image_transform_itc.bias', 'vit_model.patch_embed.proj.weight', 'vit_model.patch_embed.proj.bias', 'vit_model.patch_embed.norm.weight', 'vit_model.patch_embed.norm.bias', 'vit_model.layers.0.blocks.0.norm1.weight', 'vit_model.layers.0.blocks.0.norm1.bias', 'vit_model.layers.0.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.0.attn.relative_position_index', 'vit_model.layers.0.blocks.0.attn.qkv.weight', 'vit_model.layers.0.blocks.0.attn.qkv.bias', 'vit_model.layers.0.blocks.0.attn.proj.weight', 'vit_model.layers.0.blocks.0.attn.proj.bias', 'vit_model.layers.0.blocks.0.norm2.weight', 'vit_model.layers.0.blocks.0.norm2.bias', 'vit_model.layers.0.blocks.0.mlp.fc1.weight', 'vit_model.layers.0.blocks.0.mlp.fc1.bias', 'vit_model.layers.0.blocks.0.mlp.fc2.weight', 'vit_model.layers.0.blocks.0.mlp.fc2.bias', 'vit_model.layers.0.blocks.1.attn_mask', 'vit_model.layers.0.blocks.1.norm1.weight', 'vit_model.layers.0.blocks.1.norm1.bias', 'vit_model.layers.0.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.1.attn.relative_position_index', 'vit_model.layers.0.blocks.1.attn.qkv.weight', 'vit_model.layers.0.blocks.1.attn.qkv.bias', 'vit_model.layers.0.blocks.1.attn.proj.weight', 'vit_model.layers.0.blocks.1.attn.proj.bias', 'vit_model.layers.0.blocks.1.norm2.weight', 'vit_model.layers.0.blocks.1.norm2.bias', 'vit_model.layers.0.blocks.1.mlp.fc1.weight', 'vit_model.layers.0.blocks.1.mlp.fc1.bias', 'vit_model.layers.0.blocks.1.mlp.fc2.weight', 'vit_model.layers.0.blocks.1.mlp.fc2.bias', 'vit_model.layers.0.downsample.reduction.weight', 'vit_model.layers.0.downsample.norm.weight', 'vit_model.layers.0.downsample.norm.bias', 'vit_model.layers.1.blocks.0.norm1.weight', 'vit_model.layers.1.blocks.0.norm1.bias', 'vit_model.layers.1.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.0.attn.relative_position_index', 'vit_model.layers.1.blocks.0.attn.qkv.weight', 'vit_model.layers.1.blocks.0.attn.qkv.bias', 'vit_model.layers.1.blocks.0.attn.proj.weight', 'vit_model.layers.1.blocks.0.attn.proj.bias', 'vit_model.layers.1.blocks.0.norm2.weight', 'vit_model.layers.1.blocks.0.norm2.bias', 'vit_model.layers.1.blocks.0.mlp.fc1.weight', 'vit_model.layers.1.blocks.0.mlp.fc1.bias', 'vit_model.layers.1.blocks.0.mlp.fc2.weight', 'vit_model.layers.1.blocks.0.mlp.fc2.bias', 'vit_model.layers.1.blocks.1.attn_mask', 'vit_model.layers.1.blocks.1.norm1.weight', 'vit_model.layers.1.blocks.1.norm1.bias', 'vit_model.layers.1.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.1.attn.relative_position_index', 'vit_model.layers.1.blocks.1.attn.qkv.weight', 'vit_model.layers.1.blocks.1.attn.qkv.bias', 'vit_model.layers.1.blocks.1.attn.proj.weight', 'vit_model.layers.1.blocks.1.attn.proj.bias', 'vit_model.layers.1.blocks.1.norm2.weight', 'vit_model.layers.1.blocks.1.norm2.bias', 'vit_model.layers.1.blocks.1.mlp.fc1.weight', 'vit_model.layers.1.blocks.1.mlp.fc1.bias', 'vit_model.layers.1.blocks.1.mlp.fc2.weight', 'vit_model.layers.1.blocks.1.mlp.fc2.bias', 'vit_model.layers.1.downsample.reduction.weight', 'vit_model.layers.1.downsample.norm.weight', 'vit_model.layers.1.downsample.norm.bias', 'vit_model.layers.2.blocks.0.norm1.weight', 'vit_model.layers.2.blocks.0.norm1.bias', 'vit_model.layers.2.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.0.attn.relative_position_index', 'vit_model.layers.2.blocks.0.attn.qkv.weight', 'vit_model.layers.2.blocks.0.attn.qkv.bias', 'vit_model.layers.2.blocks.0.attn.proj.weight', 'vit_model.layers.2.blocks.0.attn.proj.bias', 'vit_model.layers.2.blocks.0.norm2.weight', 'vit_model.layers.2.blocks.0.norm2.bias', 'vit_model.layers.2.blocks.0.mlp.fc1.weight', 'vit_model.layers.2.blocks.0.mlp.fc1.bias', 'vit_model.layers.2.blocks.0.mlp.fc2.weight', 'vit_model.layers.2.blocks.0.mlp.fc2.bias', 'vit_model.layers.2.blocks.1.attn_mask', 'vit_model.layers.2.blocks.1.norm1.weight', 'vit_model.layers.2.blocks.1.norm1.bias', 'vit_model.layers.2.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.1.attn.relative_position_index', 'vit_model.layers.2.blocks.1.attn.qkv.weight', 'vit_model.layers.2.blocks.1.attn.qkv.bias', 'vit_model.layers.2.blocks.1.attn.proj.weight', 'vit_model.layers.2.blocks.1.attn.proj.bias', 'vit_model.layers.2.blocks.1.norm2.weight', 'vit_model.layers.2.blocks.1.norm2.bias', 'vit_model.layers.2.blocks.1.mlp.fc1.weight', 'vit_model.layers.2.blocks.1.mlp.fc1.bias', 'vit_model.layers.2.blocks.1.mlp.fc2.weight', 'vit_model.layers.2.blocks.1.mlp.fc2.bias', 'vit_model.layers.2.blocks.2.norm1.weight', 'vit_model.layers.2.blocks.2.norm1.bias', 'vit_model.layers.2.blocks.2.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.2.attn.relative_position_index', 'vit_model.layers.2.blocks.2.attn.qkv.weight', 'vit_model.layers.2.blocks.2.attn.qkv.bias', 'vit_model.layers.2.blocks.2.attn.proj.weight', 'vit_model.layers.2.blocks.2.attn.proj.bias', 'vit_model.layers.2.blocks.2.norm2.weight', 'vit_model.layers.2.blocks.2.norm2.bias', 'vit_model.layers.2.blocks.2.mlp.fc1.weight', 'vit_model.layers.2.blocks.2.mlp.fc1.bias', 'vit_model.layers.2.blocks.2.mlp.fc2.weight', 'vit_model.layers.2.blocks.2.mlp.fc2.bias', 'vit_model.layers.2.blocks.3.attn_mask', 'vit_model.layers.2.blocks.3.norm1.weight', 'vit_model.layers.2.blocks.3.norm1.bias', 'vit_model.layers.2.blocks.3.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.3.attn.relative_position_index', 'vit_model.layers.2.blocks.3.attn.qkv.weight', 'vit_model.layers.2.blocks.3.attn.qkv.bias', 'vit_model.layers.2.blocks.3.attn.proj.weight', 'vit_model.layers.2.blocks.3.attn.proj.bias', 'vit_model.layers.2.blocks.3.norm2.weight', 'vit_model.layers.2.blocks.3.norm2.bias', 'vit_model.layers.2.blocks.3.mlp.fc1.weight', 'vit_model.layers.2.blocks.3.mlp.fc1.bias', 'vit_model.layers.2.blocks.3.mlp.fc2.weight', 'vit_model.layers.2.blocks.3.mlp.fc2.bias', 'vit_model.layers.2.blocks.4.norm1.weight', 'vit_model.layers.2.blocks.4.norm1.bias', 'vit_model.layers.2.blocks.4.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.4.attn.relative_position_index', 'vit_model.layers.2.blocks.4.attn.qkv.weight', 'vit_model.layers.2.blocks.4.attn.qkv.bias', 'vit_model.layers.2.blocks.4.attn.proj.weight', 'vit_model.layers.2.blocks.4.attn.proj.bias', 'vit_model.layers.2.blocks.4.norm2.weight', 'vit_model.layers.2.blocks.4.norm2.bias', 'vit_model.layers.2.blocks.4.mlp.fc1.weight', 'vit_model.layers.2.blocks.4.mlp.fc1.bias', 'vit_model.layers.2.blocks.4.mlp.fc2.weight', 'vit_model.layers.2.blocks.4.mlp.fc2.bias', 'vit_model.layers.2.blocks.5.attn_mask', 'vit_model.layers.2.blocks.5.norm1.weight', 'vit_model.layers.2.blocks.5.norm1.bias', 'vit_model.layers.2.blocks.5.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.5.attn.relative_position_index', 'vit_model.layers.2.blocks.5.attn.qkv.weight', 'vit_model.layers.2.blocks.5.attn.qkv.bias', 'vit_model.layers.2.blocks.5.attn.proj.weight', 'vit_model.layers.2.blocks.5.attn.proj.bias', 'vit_model.layers.2.blocks.5.norm2.weight', 'vit_model.layers.2.blocks.5.norm2.bias', 'vit_model.layers.2.blocks.5.mlp.fc1.weight', 'vit_model.layers.2.blocks.5.mlp.fc1.bias', 'vit_model.layers.2.blocks.5.mlp.fc2.weight', 'vit_model.layers.2.blocks.5.mlp.fc2.bias', 'vit_model.layers.2.blocks.6.norm1.weight', 'vit_model.layers.2.blocks.6.norm1.bias', 'vit_model.layers.2.blocks.6.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.6.attn.relative_position_index', 'vit_model.layers.2.blocks.6.attn.qkv.weight', 'vit_model.layers.2.blocks.6.attn.qkv.bias', 'vit_model.layers.2.blocks.6.attn.proj.weight', 'vit_model.layers.2.blocks.6.attn.proj.bias', 'vit_model.layers.2.blocks.6.norm2.weight', 'vit_model.layers.2.blocks.6.norm2.bias', 'vit_model.layers.2.blocks.6.mlp.fc1.weight', 'vit_model.layers.2.blocks.6.mlp.fc1.bias', 'vit_model.layers.2.blocks.6.mlp.fc2.weight', 'vit_model.layers.2.blocks.6.mlp.fc2.bias', 'vit_model.layers.2.blocks.7.attn_mask', 'vit_model.layers.2.blocks.7.norm1.weight', 'vit_model.layers.2.blocks.7.norm1.bias', 'vit_model.layers.2.blocks.7.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.7.attn.relative_position_index', 'vit_model.layers.2.blocks.7.attn.qkv.weight', 'vit_model.layers.2.blocks.7.attn.qkv.bias', 'vit_model.layers.2.blocks.7.attn.proj.weight', 'vit_model.layers.2.blocks.7.attn.proj.bias', 'vit_model.layers.2.blocks.7.norm2.weight', 'vit_model.layers.2.blocks.7.norm2.bias', 'vit_model.layers.2.blocks.7.mlp.fc1.weight', 'vit_model.layers.2.blocks.7.mlp.fc1.bias', 'vit_model.layers.2.blocks.7.mlp.fc2.weight', 'vit_model.layers.2.blocks.7.mlp.fc2.bias', 'vit_model.layers.2.blocks.8.norm1.weight', 'vit_model.layers.2.blocks.8.norm1.bias', 'vit_model.layers.2.blocks.8.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.8.attn.relative_position_index', 'vit_model.layers.2.blocks.8.attn.qkv.weight', 'vit_model.layers.2.blocks.8.attn.qkv.bias', 'vit_model.layers.2.blocks.8.attn.proj.weight', 'vit_model.layers.2.blocks.8.attn.proj.bias', 'vit_model.layers.2.blocks.8.norm2.weight', 'vit_model.layers.2.blocks.8.norm2.bias', 'vit_model.layers.2.blocks.8.mlp.fc1.weight', 'vit_model.layers.2.blocks.8.mlp.fc1.bias', 'vit_model.layers.2.blocks.8.mlp.fc2.weight', 'vit_model.layers.2.blocks.8.mlp.fc2.bias', 'vit_model.layers.2.blocks.9.attn_mask', 'vit_model.layers.2.blocks.9.norm1.weight', 'vit_model.layers.2.blocks.9.norm1.bias', 'vit_model.layers.2.blocks.9.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.9.attn.relative_position_index', 'vit_model.layers.2.blocks.9.attn.qkv.weight', 'vit_model.layers.2.blocks.9.attn.qkv.bias', 'vit_model.layers.2.blocks.9.attn.proj.weight', 'vit_model.layers.2.blocks.9.attn.proj.bias', 'vit_model.layers.2.blocks.9.norm2.weight', 'vit_model.layers.2.blocks.9.norm2.bias', 'vit_model.layers.2.blocks.9.mlp.fc1.weight', 'vit_model.layers.2.blocks.9.mlp.fc1.bias', 'vit_model.layers.2.blocks.9.mlp.fc2.weight', 'vit_model.layers.2.blocks.9.mlp.fc2.bias', 'vit_model.layers.2.blocks.10.norm1.weight', 'vit_model.layers.2.blocks.10.norm1.bias', 'vit_model.layers.2.blocks.10.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.10.attn.relative_position_index', 'vit_model.layers.2.blocks.10.attn.qkv.weight', 'vit_model.layers.2.blocks.10.attn.qkv.bias', 'vit_model.layers.2.blocks.10.attn.proj.weight', 'vit_model.layers.2.blocks.10.attn.proj.bias', 'vit_model.layers.2.blocks.10.norm2.weight', 'vit_model.layers.2.blocks.10.norm2.bias', 'vit_model.layers.2.blocks.10.mlp.fc1.weight', 'vit_model.layers.2.blocks.10.mlp.fc1.bias', 'vit_model.layers.2.blocks.10.mlp.fc2.weight', 'vit_model.layers.2.blocks.10.mlp.fc2.bias', 'vit_model.layers.2.blocks.11.attn_mask', 'vit_model.layers.2.blocks.11.norm1.weight', 'vit_model.layers.2.blocks.11.norm1.bias', 'vit_model.layers.2.blocks.11.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.11.attn.relative_position_index', 'vit_model.layers.2.blocks.11.attn.qkv.weight', 'vit_model.layers.2.blocks.11.attn.qkv.bias', 'vit_model.layers.2.blocks.11.attn.proj.weight', 'vit_model.layers.2.blocks.11.attn.proj.bias', 'vit_model.layers.2.blocks.11.norm2.weight', 'vit_model.layers.2.blocks.11.norm2.bias', 'vit_model.layers.2.blocks.11.mlp.fc1.weight', 'vit_model.layers.2.blocks.11.mlp.fc1.bias', 'vit_model.layers.2.blocks.11.mlp.fc2.weight', 'vit_model.layers.2.blocks.11.mlp.fc2.bias', 'vit_model.layers.2.blocks.12.norm1.weight', 'vit_model.layers.2.blocks.12.norm1.bias', 'vit_model.layers.2.blocks.12.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.12.attn.relative_position_index', 'vit_model.layers.2.blocks.12.attn.qkv.weight', 'vit_model.layers.2.blocks.12.attn.qkv.bias', 'vit_model.layers.2.blocks.12.attn.proj.weight', 'vit_model.layers.2.blocks.12.attn.proj.bias', 'vit_model.layers.2.blocks.12.norm2.weight', 'vit_model.layers.2.blocks.12.norm2.bias', 'vit_model.layers.2.blocks.12.mlp.fc1.weight', 'vit_model.layers.2.blocks.12.mlp.fc1.bias', 'vit_model.layers.2.blocks.12.mlp.fc2.weight', 'vit_model.layers.2.blocks.12.mlp.fc2.bias', 'vit_model.layers.2.blocks.13.attn_mask', 'vit_model.layers.2.blocks.13.norm1.weight', 'vit_model.layers.2.blocks.13.norm1.bias', 'vit_model.layers.2.blocks.13.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.13.attn.relative_position_index', 'vit_model.layers.2.blocks.13.attn.qkv.weight', 'vit_model.layers.2.blocks.13.attn.qkv.bias', 'vit_model.layers.2.blocks.13.attn.proj.weight', 'vit_model.layers.2.blocks.13.attn.proj.bias', 'vit_model.layers.2.blocks.13.norm2.weight', 'vit_model.layers.2.blocks.13.norm2.bias', 'vit_model.layers.2.blocks.13.mlp.fc1.weight', 'vit_model.layers.2.blocks.13.mlp.fc1.bias', 'vit_model.layers.2.blocks.13.mlp.fc2.weight', 'vit_model.layers.2.blocks.13.mlp.fc2.bias', 'vit_model.layers.2.blocks.14.norm1.weight', 'vit_model.layers.2.blocks.14.norm1.bias', 'vit_model.layers.2.blocks.14.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.14.attn.alpha_i2t', 'vit_model.layers.2.blocks.14.attn.relative_position_index', 'vit_model.layers.2.blocks.14.attn.qkv.weight', 'vit_model.layers.2.blocks.14.attn.qkv.bias', 'vit_model.layers.2.blocks.14.attn.proj.weight', 'vit_model.layers.2.blocks.14.attn.proj.bias', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.14.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.14.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.14.norm2.weight', 'vit_model.layers.2.blocks.14.norm2.bias', 'vit_model.layers.2.blocks.14.mlp.fc1.weight', 'vit_model.layers.2.blocks.14.mlp.fc1.bias', 'vit_model.layers.2.blocks.14.mlp.fc2.weight', 'vit_model.layers.2.blocks.14.mlp.fc2.bias', 'vit_model.layers.2.blocks.15.attn_mask', 'vit_model.layers.2.blocks.15.norm1.weight', 'vit_model.layers.2.blocks.15.norm1.bias', 'vit_model.layers.2.blocks.15.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.15.attn.alpha_i2t', 'vit_model.layers.2.blocks.15.attn.relative_position_index', 'vit_model.layers.2.blocks.15.attn.qkv.weight', 'vit_model.layers.2.blocks.15.attn.qkv.bias', 'vit_model.layers.2.blocks.15.attn.proj.weight', 'vit_model.layers.2.blocks.15.attn.proj.bias', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.15.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.15.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.15.norm2.weight', 'vit_model.layers.2.blocks.15.norm2.bias', 'vit_model.layers.2.blocks.15.mlp.fc1.weight', 'vit_model.layers.2.blocks.15.mlp.fc1.bias', 'vit_model.layers.2.blocks.15.mlp.fc2.weight', 'vit_model.layers.2.blocks.15.mlp.fc2.bias', 'vit_model.layers.2.blocks.16.norm1.weight', 'vit_model.layers.2.blocks.16.norm1.bias', 'vit_model.layers.2.blocks.16.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.16.attn.alpha_i2t', 'vit_model.layers.2.blocks.16.attn.relative_position_index', 'vit_model.layers.2.blocks.16.attn.qkv.weight', 'vit_model.layers.2.blocks.16.attn.qkv.bias', 'vit_model.layers.2.blocks.16.attn.proj.weight', 'vit_model.layers.2.blocks.16.attn.proj.bias', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.16.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.16.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.16.norm2.weight', 'vit_model.layers.2.blocks.16.norm2.bias', 'vit_model.layers.2.blocks.16.mlp.fc1.weight', 'vit_model.layers.2.blocks.16.mlp.fc1.bias', 'vit_model.layers.2.blocks.16.mlp.fc2.weight', 'vit_model.layers.2.blocks.16.mlp.fc2.bias', 'vit_model.layers.2.blocks.17.attn_mask', 'vit_model.layers.2.blocks.17.norm1.weight', 'vit_model.layers.2.blocks.17.norm1.bias', 'vit_model.layers.2.blocks.17.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.17.attn.alpha_i2t', 'vit_model.layers.2.blocks.17.attn.relative_position_index', 'vit_model.layers.2.blocks.17.attn.qkv.weight', 'vit_model.layers.2.blocks.17.attn.qkv.bias', 'vit_model.layers.2.blocks.17.attn.proj.weight', 'vit_model.layers.2.blocks.17.attn.proj.bias', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.17.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.17.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.17.norm2.weight', 'vit_model.layers.2.blocks.17.norm2.bias', 'vit_model.layers.2.blocks.17.mlp.fc1.weight', 'vit_model.layers.2.blocks.17.mlp.fc1.bias', 'vit_model.layers.2.blocks.17.mlp.fc2.weight', 'vit_model.layers.2.blocks.17.mlp.fc2.bias', 'vit_model.layers.2.downsample.reduction.weight', 'vit_model.layers.2.downsample.norm.weight', 'vit_model.layers.2.downsample.norm.bias', 'vit_model.layers.3.blocks.0.norm1.weight', 'vit_model.layers.3.blocks.0.norm1.bias', 'vit_model.layers.3.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.0.attn.alpha_i2t', 'vit_model.layers.3.blocks.0.attn.relative_position_index', 'vit_model.layers.3.blocks.0.attn.qkv.weight', 'vit_model.layers.3.blocks.0.attn.qkv.bias', 'vit_model.layers.3.blocks.0.attn.proj.weight', 'vit_model.layers.3.blocks.0.attn.proj.bias', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.0.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.0.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.0.norm2.weight', 'vit_model.layers.3.blocks.0.norm2.bias', 'vit_model.layers.3.blocks.0.mlp.fc1.weight', 'vit_model.layers.3.blocks.0.mlp.fc1.bias', 'vit_model.layers.3.blocks.0.mlp.fc2.weight', 'vit_model.layers.3.blocks.0.mlp.fc2.bias', 'vit_model.layers.3.blocks.1.norm1.weight', 'vit_model.layers.3.blocks.1.norm1.bias', 'vit_model.layers.3.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.1.attn.alpha_i2t', 'vit_model.layers.3.blocks.1.attn.relative_position_index', 'vit_model.layers.3.blocks.1.attn.qkv.weight', 'vit_model.layers.3.blocks.1.attn.qkv.bias', 'vit_model.layers.3.blocks.1.attn.proj.weight', 'vit_model.layers.3.blocks.1.attn.proj.bias', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.1.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.1.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.1.norm2.weight', 'vit_model.layers.3.blocks.1.norm2.bias', 'vit_model.layers.3.blocks.1.mlp.fc1.weight', 'vit_model.layers.3.blocks.1.mlp.fc1.bias', 'vit_model.layers.3.blocks.1.mlp.fc2.weight', 'vit_model.layers.3.blocks.1.mlp.fc2.bias', 'vit_model.norm.weight', 'vit_model.norm.bias', 'text_transformer.embeddings.position_ids', 'text_transformer.embeddings.word_embeddings.weight', 'text_transformer.embeddings.position_embeddings.weight', 'text_transformer.embeddings.token_type_embeddings.weight', 'text_transformer.embeddings.LayerNorm.weight', 'text_transformer.embeddings.LayerNorm.bias', 'text_transformer.encoder.layer.0.alpha_t2i', 'text_transformer.encoder.layer.0.attention.self.query.weight', 'text_transformer.encoder.layer.0.attention.self.query.bias', 'text_transformer.encoder.layer.0.attention.self.key.weight', 'text_transformer.encoder.layer.0.attention.self.key.bias', 'text_transformer.encoder.layer.0.attention.self.value.weight', 'text_transformer.encoder.layer.0.attention.self.value.bias', 'text_transformer.encoder.layer.0.attention.output.dense.weight', 'text_transformer.encoder.layer.0.attention.output.dense.bias', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.0.intermediate.dense.weight', 'text_transformer.encoder.layer.0.intermediate.dense.bias', 'text_transformer.encoder.layer.0.output.dense.weight', 'text_transformer.encoder.layer.0.output.dense.bias', 'text_transformer.encoder.layer.0.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.alpha_t2i', 'text_transformer.encoder.layer.1.attention.self.query.weight', 'text_transformer.encoder.layer.1.attention.self.query.bias', 'text_transformer.encoder.layer.1.attention.self.key.weight', 'text_transformer.encoder.layer.1.attention.self.key.bias', 'text_transformer.encoder.layer.1.attention.self.value.weight', 'text_transformer.encoder.layer.1.attention.self.value.bias', 'text_transformer.encoder.layer.1.attention.output.dense.weight', 'text_transformer.encoder.layer.1.attention.output.dense.bias', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.intermediate.dense.weight', 'text_transformer.encoder.layer.1.intermediate.dense.bias', 'text_transformer.encoder.layer.1.output.dense.weight', 'text_transformer.encoder.layer.1.output.dense.bias', 'text_transformer.encoder.layer.1.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.alpha_t2i', 'text_transformer.encoder.layer.2.attention.self.query.weight', 'text_transformer.encoder.layer.2.attention.self.query.bias', 'text_transformer.encoder.layer.2.attention.self.key.weight', 'text_transformer.encoder.layer.2.attention.self.key.bias', 'text_transformer.encoder.layer.2.attention.self.value.weight', 'text_transformer.encoder.layer.2.attention.self.value.bias', 'text_transformer.encoder.layer.2.attention.output.dense.weight', 'text_transformer.encoder.layer.2.attention.output.dense.bias', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.intermediate.dense.weight', 'text_transformer.encoder.layer.2.intermediate.dense.bias', 'text_transformer.encoder.layer.2.output.dense.weight', 'text_transformer.encoder.layer.2.output.dense.bias', 'text_transformer.encoder.layer.2.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.alpha_t2i', 'text_transformer.encoder.layer.3.attention.self.query.weight', 'text_transformer.encoder.layer.3.attention.self.query.bias', 'text_transformer.encoder.layer.3.attention.self.key.weight', 'text_transformer.encoder.layer.3.attention.self.key.bias', 'text_transformer.encoder.layer.3.attention.self.value.weight', 'text_transformer.encoder.layer.3.attention.self.value.bias', 'text_transformer.encoder.layer.3.attention.output.dense.weight', 'text_transformer.encoder.layer.3.attention.output.dense.bias', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.intermediate.dense.weight', 'text_transformer.encoder.layer.3.intermediate.dense.bias', 'text_transformer.encoder.layer.3.output.dense.weight', 'text_transformer.encoder.layer.3.output.dense.bias', 'text_transformer.encoder.layer.3.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.alpha_t2i', 'text_transformer.encoder.layer.4.attention.self.query.weight', 'text_transformer.encoder.layer.4.attention.self.query.bias', 'text_transformer.encoder.layer.4.attention.self.key.weight', 'text_transformer.encoder.layer.4.attention.self.key.bias', 'text_transformer.encoder.layer.4.attention.self.value.weight', 'text_transformer.encoder.layer.4.attention.self.value.bias', 'text_transformer.encoder.layer.4.attention.output.dense.weight', 'text_transformer.encoder.layer.4.attention.output.dense.bias', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.intermediate.dense.weight', 'text_transformer.encoder.layer.4.intermediate.dense.bias', 'text_transformer.encoder.layer.4.output.dense.weight', 'text_transformer.encoder.layer.4.output.dense.bias', 'text_transformer.encoder.layer.4.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.alpha_t2i', 'text_transformer.encoder.layer.5.attention.self.query.weight', 'text_transformer.encoder.layer.5.attention.self.query.bias', 'text_transformer.encoder.layer.5.attention.self.key.weight', 'text_transformer.encoder.layer.5.attention.self.key.bias', 'text_transformer.encoder.layer.5.attention.self.value.weight', 'text_transformer.encoder.layer.5.attention.self.value.bias', 'text_transformer.encoder.layer.5.attention.output.dense.weight', 'text_transformer.encoder.layer.5.attention.output.dense.bias', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.intermediate.dense.weight', 'text_transformer.encoder.layer.5.intermediate.dense.bias', 'text_transformer.encoder.layer.5.output.dense.weight', 'text_transformer.encoder.layer.5.output.dense.bias', 'text_transformer.encoder.layer.5.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.alpha_t2i', 'text_transformer.encoder.layer.6.attention.self.query.weight', 'text_transformer.encoder.layer.6.attention.self.query.bias', 'text_transformer.encoder.layer.6.attention.self.key.weight', 'text_transformer.encoder.layer.6.attention.self.key.bias', 'text_transformer.encoder.layer.6.attention.self.value.weight', 'text_transformer.encoder.layer.6.attention.self.value.bias', 'text_transformer.encoder.layer.6.attention.output.dense.weight', 'text_transformer.encoder.layer.6.attention.output.dense.bias', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.intermediate.dense.weight', 'text_transformer.encoder.layer.6.intermediate.dense.bias', 'text_transformer.encoder.layer.6.output.dense.weight', 'text_transformer.encoder.layer.6.output.dense.bias', 'text_transformer.encoder.layer.6.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.alpha_t2i', 'text_transformer.encoder.layer.7.attention.self.query.weight', 'text_transformer.encoder.layer.7.attention.self.query.bias', 'text_transformer.encoder.layer.7.attention.self.key.weight', 'text_transformer.encoder.layer.7.attention.self.key.bias', 'text_transformer.encoder.layer.7.attention.self.value.weight', 'text_transformer.encoder.layer.7.attention.self.value.bias', 'text_transformer.encoder.layer.7.attention.output.dense.weight', 'text_transformer.encoder.layer.7.attention.output.dense.bias', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.intermediate.dense.weight', 'text_transformer.encoder.layer.7.intermediate.dense.bias', 'text_transformer.encoder.layer.7.output.dense.weight', 'text_transformer.encoder.layer.7.output.dense.bias', 'text_transformer.encoder.layer.7.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.alpha_t2i', 'text_transformer.encoder.layer.8.attention.self.query.weight', 'text_transformer.encoder.layer.8.attention.self.query.bias', 'text_transformer.encoder.layer.8.attention.self.key.weight', 'text_transformer.encoder.layer.8.attention.self.key.bias', 'text_transformer.encoder.layer.8.attention.self.value.weight', 'text_transformer.encoder.layer.8.attention.self.value.bias', 'text_transformer.encoder.layer.8.attention.output.dense.weight', 'text_transformer.encoder.layer.8.attention.output.dense.bias', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.intermediate.dense.weight', 'text_transformer.encoder.layer.8.intermediate.dense.bias', 'text_transformer.encoder.layer.8.output.dense.weight', 'text_transformer.encoder.layer.8.output.dense.bias', 'text_transformer.encoder.layer.8.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.alpha_t2i', 'text_transformer.encoder.layer.9.attention.self.query.weight', 'text_transformer.encoder.layer.9.attention.self.query.bias', 'text_transformer.encoder.layer.9.attention.self.key.weight', 'text_transformer.encoder.layer.9.attention.self.key.bias', 'text_transformer.encoder.layer.9.attention.self.value.weight', 'text_transformer.encoder.layer.9.attention.self.value.bias', 'text_transformer.encoder.layer.9.attention.output.dense.weight', 'text_transformer.encoder.layer.9.attention.output.dense.bias', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.intermediate.dense.weight', 'text_transformer.encoder.layer.9.intermediate.dense.bias', 'text_transformer.encoder.layer.9.output.dense.weight', 'text_transformer.encoder.layer.9.output.dense.bias', 'text_transformer.encoder.layer.9.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.alpha_t2i', 'text_transformer.encoder.layer.10.attention.self.query.weight', 'text_transformer.encoder.layer.10.attention.self.query.bias', 'text_transformer.encoder.layer.10.attention.self.key.weight', 'text_transformer.encoder.layer.10.attention.self.key.bias', 'text_transformer.encoder.layer.10.attention.self.value.weight', 'text_transformer.encoder.layer.10.attention.self.value.bias', 'text_transformer.encoder.layer.10.attention.output.dense.weight', 'text_transformer.encoder.layer.10.attention.output.dense.bias', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.intermediate.dense.weight', 'text_transformer.encoder.layer.10.intermediate.dense.bias', 'text_transformer.encoder.layer.10.output.dense.weight', 'text_transformer.encoder.layer.10.output.dense.bias', 'text_transformer.encoder.layer.10.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.alpha_t2i', 'text_transformer.encoder.layer.11.attention.self.query.weight', 'text_transformer.encoder.layer.11.attention.self.query.bias', 'text_transformer.encoder.layer.11.attention.self.key.weight', 'text_transformer.encoder.layer.11.attention.self.key.bias', 'text_transformer.encoder.layer.11.attention.self.value.weight', 'text_transformer.encoder.layer.11.attention.self.value.bias', 'text_transformer.encoder.layer.11.attention.output.dense.weight', 'text_transformer.encoder.layer.11.attention.output.dense.bias', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.intermediate.dense.weight', 'text_transformer.encoder.layer.11.intermediate.dense.bias', 'text_transformer.encoder.layer.11.output.dense.weight', 'text_transformer.encoder.layer.11.output.dense.bias', 'text_transformer.encoder.layer.11.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.output.LayerNorm.bias', 'text_transformer.pooler.dense.weight', 'text_transformer.pooler.dense.bias', 'cross_modal_image_pooler.dense.weight', 'cross_modal_image_pooler.dense.bias', 'cross_modal_text_pooler.dense.weight', 'cross_modal_text_pooler.dense.bias', 'cross_modal_image_pooler_itc.dense.weight', 'cross_modal_image_pooler_itc.dense.bias', 'cross_modal_text_pooler_itc.dense.weight', 'cross_modal_text_pooler_itc.dense.bias', 'vqa_classifier.model.0.weight', 'vqa_classifier.model.0.bias', 'vqa_classifier.model.1.weight', 'vqa_classifier.model.1.bias', 'vqa_classifier.model.3.weight', 'vqa_classifier.model.3.bias'])
image_state_dict.keys(): odict_keys(['cross_modal_text_transform.weight', 'cross_modal_text_transform.bias', 'cross_modal_image_transform.weight', 'cross_modal_image_transform.bias', 'cross_modal_text_transform_itc.weight', 'cross_modal_text_transform_itc.bias', 'cross_modal_image_transform_itc.weight', 'cross_modal_image_transform_itc.bias', 'vit_model.patch_embed.proj.weight', 'vit_model.patch_embed.proj.bias', 'vit_model.patch_embed.norm.weight', 'vit_model.patch_embed.norm.bias', 'vit_model.layers.0.blocks.0.norm1.weight', 'vit_model.layers.0.blocks.0.norm1.bias', 'vit_model.layers.0.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.0.attn.relative_position_index', 'vit_model.layers.0.blocks.0.attn.qkv.weight', 'vit_model.layers.0.blocks.0.attn.qkv.bias', 'vit_model.layers.0.blocks.0.attn.proj.weight', 'vit_model.layers.0.blocks.0.attn.proj.bias', 'vit_model.layers.0.blocks.0.norm2.weight', 'vit_model.layers.0.blocks.0.norm2.bias', 'vit_model.layers.0.blocks.0.mlp.fc1.weight', 'vit_model.layers.0.blocks.0.mlp.fc1.bias', 'vit_model.layers.0.blocks.0.mlp.fc2.weight', 'vit_model.layers.0.blocks.0.mlp.fc2.bias', 'vit_model.layers.0.blocks.1.attn_mask', 'vit_model.layers.0.blocks.1.norm1.weight', 'vit_model.layers.0.blocks.1.norm1.bias', 'vit_model.layers.0.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.1.attn.relative_position_index', 'vit_model.layers.0.blocks.1.attn.qkv.weight', 'vit_model.layers.0.blocks.1.attn.qkv.bias', 'vit_model.layers.0.blocks.1.attn.proj.weight', 'vit_model.layers.0.blocks.1.attn.proj.bias', 'vit_model.layers.0.blocks.1.norm2.weight', 'vit_model.layers.0.blocks.1.norm2.bias', 'vit_model.layers.0.blocks.1.mlp.fc1.weight', 'vit_model.layers.0.blocks.1.mlp.fc1.bias', 'vit_model.layers.0.blocks.1.mlp.fc2.weight', 'vit_model.layers.0.blocks.1.mlp.fc2.bias', 'vit_model.layers.0.downsample.reduction.weight', 'vit_model.layers.0.downsample.norm.weight', 'vit_model.layers.0.downsample.norm.bias', 'vit_model.layers.1.blocks.0.norm1.weight', 'vit_model.layers.1.blocks.0.norm1.bias', 'vit_model.layers.1.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.0.attn.relative_position_index', 'vit_model.layers.1.blocks.0.attn.qkv.weight', 'vit_model.layers.1.blocks.0.attn.qkv.bias', 'vit_model.layers.1.blocks.0.attn.proj.weight', 'vit_model.layers.1.blocks.0.attn.proj.bias', 'vit_model.layers.1.blocks.0.norm2.weight', 'vit_model.layers.1.blocks.0.norm2.bias', 'vit_model.layers.1.blocks.0.mlp.fc1.weight', 'vit_model.layers.1.blocks.0.mlp.fc1.bias', 'vit_model.layers.1.blocks.0.mlp.fc2.weight', 'vit_model.layers.1.blocks.0.mlp.fc2.bias', 'vit_model.layers.1.blocks.1.attn_mask', 'vit_model.layers.1.blocks.1.norm1.weight', 'vit_model.layers.1.blocks.1.norm1.bias', 'vit_model.layers.1.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.1.attn.relative_position_index', 'vit_model.layers.1.blocks.1.attn.qkv.weight', 'vit_model.layers.1.blocks.1.attn.qkv.bias', 'vit_model.layers.1.blocks.1.attn.proj.weight', 'vit_model.layers.1.blocks.1.attn.proj.bias', 'vit_model.layers.1.blocks.1.norm2.weight', 'vit_model.layers.1.blocks.1.norm2.bias', 'vit_model.layers.1.blocks.1.mlp.fc1.weight', 'vit_model.layers.1.blocks.1.mlp.fc1.bias', 'vit_model.layers.1.blocks.1.mlp.fc2.weight', 'vit_model.layers.1.blocks.1.mlp.fc2.bias', 'vit_model.layers.1.downsample.reduction.weight', 'vit_model.layers.1.downsample.norm.weight', 'vit_model.layers.1.downsample.norm.bias', 'vit_model.layers.2.blocks.0.norm1.weight', 'vit_model.layers.2.blocks.0.norm1.bias', 'vit_model.layers.2.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.0.attn.relative_position_index', 'vit_model.layers.2.blocks.0.attn.qkv.weight', 'vit_model.layers.2.blocks.0.attn.qkv.bias', 'vit_model.layers.2.blocks.0.attn.proj.weight', 'vit_model.layers.2.blocks.0.attn.proj.bias', 'vit_model.layers.2.blocks.0.norm2.weight', 'vit_model.layers.2.blocks.0.norm2.bias', 'vit_model.layers.2.blocks.0.mlp.fc1.weight', 'vit_model.layers.2.blocks.0.mlp.fc1.bias', 'vit_model.layers.2.blocks.0.mlp.fc2.weight', 'vit_model.layers.2.blocks.0.mlp.fc2.bias', 'vit_model.layers.2.blocks.1.attn_mask', 'vit_model.layers.2.blocks.1.norm1.weight', 'vit_model.layers.2.blocks.1.norm1.bias', 'vit_model.layers.2.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.1.attn.relative_position_index', 'vit_model.layers.2.blocks.1.attn.qkv.weight', 'vit_model.layers.2.blocks.1.attn.qkv.bias', 'vit_model.layers.2.blocks.1.attn.proj.weight', 'vit_model.layers.2.blocks.1.attn.proj.bias', 'vit_model.layers.2.blocks.1.norm2.weight', 'vit_model.layers.2.blocks.1.norm2.bias', 'vit_model.layers.2.blocks.1.mlp.fc1.weight', 'vit_model.layers.2.blocks.1.mlp.fc1.bias', 'vit_model.layers.2.blocks.1.mlp.fc2.weight', 'vit_model.layers.2.blocks.1.mlp.fc2.bias', 'vit_model.layers.2.blocks.2.norm1.weight', 'vit_model.layers.2.blocks.2.norm1.bias', 'vit_model.layers.2.blocks.2.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.2.attn.relative_position_index', 'vit_model.layers.2.blocks.2.attn.qkv.weight', 'vit_model.layers.2.blocks.2.attn.qkv.bias', 'vit_model.layers.2.blocks.2.attn.proj.weight', 'vit_model.layers.2.blocks.2.attn.proj.bias', 'vit_model.layers.2.blocks.2.norm2.weight', 'vit_model.layers.2.blocks.2.norm2.bias', 'vit_model.layers.2.blocks.2.mlp.fc1.weight', 'vit_model.layers.2.blocks.2.mlp.fc1.bias', 'vit_model.layers.2.blocks.2.mlp.fc2.weight', 'vit_model.layers.2.blocks.2.mlp.fc2.bias', 'vit_model.layers.2.blocks.3.attn_mask', 'vit_model.layers.2.blocks.3.norm1.weight', 'vit_model.layers.2.blocks.3.norm1.bias', 'vit_model.layers.2.blocks.3.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.3.attn.relative_position_index', 'vit_model.layers.2.blocks.3.attn.qkv.weight', 'vit_model.layers.2.blocks.3.attn.qkv.bias', 'vit_model.layers.2.blocks.3.attn.proj.weight', 'vit_model.layers.2.blocks.3.attn.proj.bias', 'vit_model.layers.2.blocks.3.norm2.weight', 'vit_model.layers.2.blocks.3.norm2.bias', 'vit_model.layers.2.blocks.3.mlp.fc1.weight', 'vit_model.layers.2.blocks.3.mlp.fc1.bias', 'vit_model.layers.2.blocks.3.mlp.fc2.weight', 'vit_model.layers.2.blocks.3.mlp.fc2.bias', 'vit_model.layers.2.blocks.4.norm1.weight', 'vit_model.layers.2.blocks.4.norm1.bias', 'vit_model.layers.2.blocks.4.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.4.attn.relative_position_index', 'vit_model.layers.2.blocks.4.attn.qkv.weight', 'vit_model.layers.2.blocks.4.attn.qkv.bias', 'vit_model.layers.2.blocks.4.attn.proj.weight', 'vit_model.layers.2.blocks.4.attn.proj.bias', 'vit_model.layers.2.blocks.4.norm2.weight', 'vit_model.layers.2.blocks.4.norm2.bias', 'vit_model.layers.2.blocks.4.mlp.fc1.weight', 'vit_model.layers.2.blocks.4.mlp.fc1.bias', 'vit_model.layers.2.blocks.4.mlp.fc2.weight', 'vit_model.layers.2.blocks.4.mlp.fc2.bias', 'vit_model.layers.2.blocks.5.attn_mask', 'vit_model.layers.2.blocks.5.norm1.weight', 'vit_model.layers.2.blocks.5.norm1.bias', 'vit_model.layers.2.blocks.5.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.5.attn.relative_position_index', 'vit_model.layers.2.blocks.5.attn.qkv.weight', 'vit_model.layers.2.blocks.5.attn.qkv.bias', 'vit_model.layers.2.blocks.5.attn.proj.weight', 'vit_model.layers.2.blocks.5.attn.proj.bias', 'vit_model.layers.2.blocks.5.norm2.weight', 'vit_model.layers.2.blocks.5.norm2.bias', 'vit_model.layers.2.blocks.5.mlp.fc1.weight', 'vit_model.layers.2.blocks.5.mlp.fc1.bias', 'vit_model.layers.2.blocks.5.mlp.fc2.weight', 'vit_model.layers.2.blocks.5.mlp.fc2.bias', 'vit_model.layers.2.blocks.6.norm1.weight', 'vit_model.layers.2.blocks.6.norm1.bias', 'vit_model.layers.2.blocks.6.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.6.attn.relative_position_index', 'vit_model.layers.2.blocks.6.attn.qkv.weight', 'vit_model.layers.2.blocks.6.attn.qkv.bias', 'vit_model.layers.2.blocks.6.attn.proj.weight', 'vit_model.layers.2.blocks.6.attn.proj.bias', 'vit_model.layers.2.blocks.6.norm2.weight', 'vit_model.layers.2.blocks.6.norm2.bias', 'vit_model.layers.2.blocks.6.mlp.fc1.weight', 'vit_model.layers.2.blocks.6.mlp.fc1.bias', 'vit_model.layers.2.blocks.6.mlp.fc2.weight', 'vit_model.layers.2.blocks.6.mlp.fc2.bias', 'vit_model.layers.2.blocks.7.attn_mask', 'vit_model.layers.2.blocks.7.norm1.weight', 'vit_model.layers.2.blocks.7.norm1.bias', 'vit_model.layers.2.blocks.7.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.7.attn.relative_position_index', 'vit_model.layers.2.blocks.7.attn.qkv.weight', 'vit_model.layers.2.blocks.7.attn.qkv.bias', 'vit_model.layers.2.blocks.7.attn.proj.weight', 'vit_model.layers.2.blocks.7.attn.proj.bias', 'vit_model.layers.2.blocks.7.norm2.weight', 'vit_model.layers.2.blocks.7.norm2.bias', 'vit_model.layers.2.blocks.7.mlp.fc1.weight', 'vit_model.layers.2.blocks.7.mlp.fc1.bias', 'vit_model.layers.2.blocks.7.mlp.fc2.weight', 'vit_model.layers.2.blocks.7.mlp.fc2.bias', 'vit_model.layers.2.blocks.8.norm1.weight', 'vit_model.layers.2.blocks.8.norm1.bias', 'vit_model.layers.2.blocks.8.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.8.attn.relative_position_index', 'vit_model.layers.2.blocks.8.attn.qkv.weight', 'vit_model.layers.2.blocks.8.attn.qkv.bias', 'vit_model.layers.2.blocks.8.attn.proj.weight', 'vit_model.layers.2.blocks.8.attn.proj.bias', 'vit_model.layers.2.blocks.8.norm2.weight', 'vit_model.layers.2.blocks.8.norm2.bias', 'vit_model.layers.2.blocks.8.mlp.fc1.weight', 'vit_model.layers.2.blocks.8.mlp.fc1.bias', 'vit_model.layers.2.blocks.8.mlp.fc2.weight', 'vit_model.layers.2.blocks.8.mlp.fc2.bias', 'vit_model.layers.2.blocks.9.attn_mask', 'vit_model.layers.2.blocks.9.norm1.weight', 'vit_model.layers.2.blocks.9.norm1.bias', 'vit_model.layers.2.blocks.9.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.9.attn.relative_position_index', 'vit_model.layers.2.blocks.9.attn.qkv.weight', 'vit_model.layers.2.blocks.9.attn.qkv.bias', 'vit_model.layers.2.blocks.9.attn.proj.weight', 'vit_model.layers.2.blocks.9.attn.proj.bias', 'vit_model.layers.2.blocks.9.norm2.weight', 'vit_model.layers.2.blocks.9.norm2.bias', 'vit_model.layers.2.blocks.9.mlp.fc1.weight', 'vit_model.layers.2.blocks.9.mlp.fc1.bias', 'vit_model.layers.2.blocks.9.mlp.fc2.weight', 'vit_model.layers.2.blocks.9.mlp.fc2.bias', 'vit_model.layers.2.blocks.10.norm1.weight', 'vit_model.layers.2.blocks.10.norm1.bias', 'vit_model.layers.2.blocks.10.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.10.attn.relative_position_index', 'vit_model.layers.2.blocks.10.attn.qkv.weight', 'vit_model.layers.2.blocks.10.attn.qkv.bias', 'vit_model.layers.2.blocks.10.attn.proj.weight', 'vit_model.layers.2.blocks.10.attn.proj.bias', 'vit_model.layers.2.blocks.10.norm2.weight', 'vit_model.layers.2.blocks.10.norm2.bias', 'vit_model.layers.2.blocks.10.mlp.fc1.weight', 'vit_model.layers.2.blocks.10.mlp.fc1.bias', 'vit_model.layers.2.blocks.10.mlp.fc2.weight', 'vit_model.layers.2.blocks.10.mlp.fc2.bias', 'vit_model.layers.2.blocks.11.attn_mask', 'vit_model.layers.2.blocks.11.norm1.weight', 'vit_model.layers.2.blocks.11.norm1.bias', 'vit_model.layers.2.blocks.11.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.11.attn.relative_position_index', 'vit_model.layers.2.blocks.11.attn.qkv.weight', 'vit_model.layers.2.blocks.11.attn.qkv.bias', 'vit_model.layers.2.blocks.11.attn.proj.weight', 'vit_model.layers.2.blocks.11.attn.proj.bias', 'vit_model.layers.2.blocks.11.norm2.weight', 'vit_model.layers.2.blocks.11.norm2.bias', 'vit_model.layers.2.blocks.11.mlp.fc1.weight', 'vit_model.layers.2.blocks.11.mlp.fc1.bias', 'vit_model.layers.2.blocks.11.mlp.fc2.weight', 'vit_model.layers.2.blocks.11.mlp.fc2.bias', 'vit_model.layers.2.blocks.12.norm1.weight', 'vit_model.layers.2.blocks.12.norm1.bias', 'vit_model.layers.2.blocks.12.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.12.attn.relative_position_index', 'vit_model.layers.2.blocks.12.attn.qkv.weight', 'vit_model.layers.2.blocks.12.attn.qkv.bias', 'vit_model.layers.2.blocks.12.attn.proj.weight', 'vit_model.layers.2.blocks.12.attn.proj.bias', 'vit_model.layers.2.blocks.12.norm2.weight', 'vit_model.layers.2.blocks.12.norm2.bias', 'vit_model.layers.2.blocks.12.mlp.fc1.weight', 'vit_model.layers.2.blocks.12.mlp.fc1.bias', 'vit_model.layers.2.blocks.12.mlp.fc2.weight', 'vit_model.layers.2.blocks.12.mlp.fc2.bias', 'vit_model.layers.2.blocks.13.attn_mask', 'vit_model.layers.2.blocks.13.norm1.weight', 'vit_model.layers.2.blocks.13.norm1.bias', 'vit_model.layers.2.blocks.13.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.13.attn.relative_position_index', 'vit_model.layers.2.blocks.13.attn.qkv.weight', 'vit_model.layers.2.blocks.13.attn.qkv.bias', 'vit_model.layers.2.blocks.13.attn.proj.weight', 'vit_model.layers.2.blocks.13.attn.proj.bias', 'vit_model.layers.2.blocks.13.norm2.weight', 'vit_model.layers.2.blocks.13.norm2.bias', 'vit_model.layers.2.blocks.13.mlp.fc1.weight', 'vit_model.layers.2.blocks.13.mlp.fc1.bias', 'vit_model.layers.2.blocks.13.mlp.fc2.weight', 'vit_model.layers.2.blocks.13.mlp.fc2.bias', 'vit_model.layers.2.blocks.14.norm1.weight', 'vit_model.layers.2.blocks.14.norm1.bias', 'vit_model.layers.2.blocks.14.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.14.attn.alpha_i2t', 'vit_model.layers.2.blocks.14.attn.relative_position_index', 'vit_model.layers.2.blocks.14.attn.qkv.weight', 'vit_model.layers.2.blocks.14.attn.qkv.bias', 'vit_model.layers.2.blocks.14.attn.proj.weight', 'vit_model.layers.2.blocks.14.attn.proj.bias', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.14.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.14.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.14.norm2.weight', 'vit_model.layers.2.blocks.14.norm2.bias', 'vit_model.layers.2.blocks.14.mlp.fc1.weight', 'vit_model.layers.2.blocks.14.mlp.fc1.bias', 'vit_model.layers.2.blocks.14.mlp.fc2.weight', 'vit_model.layers.2.blocks.14.mlp.fc2.bias', 'vit_model.layers.2.blocks.15.attn_mask', 'vit_model.layers.2.blocks.15.norm1.weight', 'vit_model.layers.2.blocks.15.norm1.bias', 'vit_model.layers.2.blocks.15.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.15.attn.alpha_i2t', 'vit_model.layers.2.blocks.15.attn.relative_position_index', 'vit_model.layers.2.blocks.15.attn.qkv.weight', 'vit_model.layers.2.blocks.15.attn.qkv.bias', 'vit_model.layers.2.blocks.15.attn.proj.weight', 'vit_model.layers.2.blocks.15.attn.proj.bias', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.15.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.15.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.15.norm2.weight', 'vit_model.layers.2.blocks.15.norm2.bias', 'vit_model.layers.2.blocks.15.mlp.fc1.weight', 'vit_model.layers.2.blocks.15.mlp.fc1.bias', 'vit_model.layers.2.blocks.15.mlp.fc2.weight', 'vit_model.layers.2.blocks.15.mlp.fc2.bias', 'vit_model.layers.2.blocks.16.norm1.weight', 'vit_model.layers.2.blocks.16.norm1.bias', 'vit_model.layers.2.blocks.16.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.16.attn.alpha_i2t', 'vit_model.layers.2.blocks.16.attn.relative_position_index', 'vit_model.layers.2.blocks.16.attn.qkv.weight', 'vit_model.layers.2.blocks.16.attn.qkv.bias', 'vit_model.layers.2.blocks.16.attn.proj.weight', 'vit_model.layers.2.blocks.16.attn.proj.bias', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.16.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.16.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.16.norm2.weight', 'vit_model.layers.2.blocks.16.norm2.bias', 'vit_model.layers.2.blocks.16.mlp.fc1.weight', 'vit_model.layers.2.blocks.16.mlp.fc1.bias', 'vit_model.layers.2.blocks.16.mlp.fc2.weight', 'vit_model.layers.2.blocks.16.mlp.fc2.bias', 'vit_model.layers.2.blocks.17.attn_mask', 'vit_model.layers.2.blocks.17.norm1.weight', 'vit_model.layers.2.blocks.17.norm1.bias', 'vit_model.layers.2.blocks.17.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.17.attn.alpha_i2t', 'vit_model.layers.2.blocks.17.attn.relative_position_index', 'vit_model.layers.2.blocks.17.attn.qkv.weight', 'vit_model.layers.2.blocks.17.attn.qkv.bias', 'vit_model.layers.2.blocks.17.attn.proj.weight', 'vit_model.layers.2.blocks.17.attn.proj.bias', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.17.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.17.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.17.norm2.weight', 'vit_model.layers.2.blocks.17.norm2.bias', 'vit_model.layers.2.blocks.17.mlp.fc1.weight', 'vit_model.layers.2.blocks.17.mlp.fc1.bias', 'vit_model.layers.2.blocks.17.mlp.fc2.weight', 'vit_model.layers.2.blocks.17.mlp.fc2.bias', 'vit_model.layers.2.downsample.reduction.weight', 'vit_model.layers.2.downsample.norm.weight', 'vit_model.layers.2.downsample.norm.bias', 'vit_model.layers.3.blocks.0.norm1.weight', 'vit_model.layers.3.blocks.0.norm1.bias', 'vit_model.layers.3.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.0.attn.alpha_i2t', 'vit_model.layers.3.blocks.0.attn.relative_position_index', 'vit_model.layers.3.blocks.0.attn.qkv.weight', 'vit_model.layers.3.blocks.0.attn.qkv.bias', 'vit_model.layers.3.blocks.0.attn.proj.weight', 'vit_model.layers.3.blocks.0.attn.proj.bias', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.0.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.0.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.0.norm2.weight', 'vit_model.layers.3.blocks.0.norm2.bias', 'vit_model.layers.3.blocks.0.mlp.fc1.weight', 'vit_model.layers.3.blocks.0.mlp.fc1.bias', 'vit_model.layers.3.blocks.0.mlp.fc2.weight', 'vit_model.layers.3.blocks.0.mlp.fc2.bias', 'vit_model.layers.3.blocks.1.norm1.weight', 'vit_model.layers.3.blocks.1.norm1.bias', 'vit_model.layers.3.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.1.attn.alpha_i2t', 'vit_model.layers.3.blocks.1.attn.relative_position_index', 'vit_model.layers.3.blocks.1.attn.qkv.weight', 'vit_model.layers.3.blocks.1.attn.qkv.bias', 'vit_model.layers.3.blocks.1.attn.proj.weight', 'vit_model.layers.3.blocks.1.attn.proj.bias', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.1.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.1.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.1.norm2.weight', 'vit_model.layers.3.blocks.1.norm2.bias', 'vit_model.layers.3.blocks.1.mlp.fc1.weight', 'vit_model.layers.3.blocks.1.mlp.fc1.bias', 'vit_model.layers.3.blocks.1.mlp.fc2.weight', 'vit_model.layers.3.blocks.1.mlp.fc2.bias', 'vit_model.norm.weight', 'vit_model.norm.bias', 'text_transformer.embeddings.position_ids', 'text_transformer.embeddings.word_embeddings.weight', 'text_transformer.embeddings.position_embeddings.weight', 'text_transformer.embeddings.token_type_embeddings.weight', 'text_transformer.embeddings.LayerNorm.weight', 'text_transformer.embeddings.LayerNorm.bias', 'text_transformer.encoder.layer.0.alpha_t2i', 'text_transformer.encoder.layer.0.attention.self.query.weight', 'text_transformer.encoder.layer.0.attention.self.query.bias', 'text_transformer.encoder.layer.0.attention.self.key.weight', 'text_transformer.encoder.layer.0.attention.self.key.bias', 'text_transformer.encoder.layer.0.attention.self.value.weight', 'text_transformer.encoder.layer.0.attention.self.value.bias', 'text_transformer.encoder.layer.0.attention.output.dense.weight', 'text_transformer.encoder.layer.0.attention.output.dense.bias', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.0.intermediate.dense.weight', 'text_transformer.encoder.layer.0.intermediate.dense.bias', 'text_transformer.encoder.layer.0.output.dense.weight', 'text_transformer.encoder.layer.0.output.dense.bias', 'text_transformer.encoder.layer.0.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.alpha_t2i', 'text_transformer.encoder.layer.1.attention.self.query.weight', 'text_transformer.encoder.layer.1.attention.self.query.bias', 'text_transformer.encoder.layer.1.attention.self.key.weight', 'text_transformer.encoder.layer.1.attention.self.key.bias', 'text_transformer.encoder.layer.1.attention.self.value.weight', 'text_transformer.encoder.layer.1.attention.self.value.bias', 'text_transformer.encoder.layer.1.attention.output.dense.weight', 'text_transformer.encoder.layer.1.attention.output.dense.bias', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.intermediate.dense.weight', 'text_transformer.encoder.layer.1.intermediate.dense.bias', 'text_transformer.encoder.layer.1.output.dense.weight', 'text_transformer.encoder.layer.1.output.dense.bias', 'text_transformer.encoder.layer.1.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.alpha_t2i', 'text_transformer.encoder.layer.2.attention.self.query.weight', 'text_transformer.encoder.layer.2.attention.self.query.bias', 'text_transformer.encoder.layer.2.attention.self.key.weight', 'text_transformer.encoder.layer.2.attention.self.key.bias', 'text_transformer.encoder.layer.2.attention.self.value.weight', 'text_transformer.encoder.layer.2.attention.self.value.bias', 'text_transformer.encoder.layer.2.attention.output.dense.weight', 'text_transformer.encoder.layer.2.attention.output.dense.bias', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.intermediate.dense.weight', 'text_transformer.encoder.layer.2.intermediate.dense.bias', 'text_transformer.encoder.layer.2.output.dense.weight', 'text_transformer.encoder.layer.2.output.dense.bias', 'text_transformer.encoder.layer.2.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.alpha_t2i', 'text_transformer.encoder.layer.3.attention.self.query.weight', 'text_transformer.encoder.layer.3.attention.self.query.bias', 'text_transformer.encoder.layer.3.attention.self.key.weight', 'text_transformer.encoder.layer.3.attention.self.key.bias', 'text_transformer.encoder.layer.3.attention.self.value.weight', 'text_transformer.encoder.layer.3.attention.self.value.bias', 'text_transformer.encoder.layer.3.attention.output.dense.weight', 'text_transformer.encoder.layer.3.attention.output.dense.bias', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.intermediate.dense.weight', 'text_transformer.encoder.layer.3.intermediate.dense.bias', 'text_transformer.encoder.layer.3.output.dense.weight', 'text_transformer.encoder.layer.3.output.dense.bias', 'text_transformer.encoder.layer.3.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.alpha_t2i', 'text_transformer.encoder.layer.4.attention.self.query.weight', 'text_transformer.encoder.layer.4.attention.self.query.bias', 'text_transformer.encoder.layer.4.attention.self.key.weight', 'text_transformer.encoder.layer.4.attention.self.key.bias', 'text_transformer.encoder.layer.4.attention.self.value.weight', 'text_transformer.encoder.layer.4.attention.self.value.bias', 'text_transformer.encoder.layer.4.attention.output.dense.weight', 'text_transformer.encoder.layer.4.attention.output.dense.bias', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.intermediate.dense.weight', 'text_transformer.encoder.layer.4.intermediate.dense.bias', 'text_transformer.encoder.layer.4.output.dense.weight', 'text_transformer.encoder.layer.4.output.dense.bias', 'text_transformer.encoder.layer.4.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.alpha_t2i', 'text_transformer.encoder.layer.5.attention.self.query.weight', 'text_transformer.encoder.layer.5.attention.self.query.bias', 'text_transformer.encoder.layer.5.attention.self.key.weight', 'text_transformer.encoder.layer.5.attention.self.key.bias', 'text_transformer.encoder.layer.5.attention.self.value.weight', 'text_transformer.encoder.layer.5.attention.self.value.bias', 'text_transformer.encoder.layer.5.attention.output.dense.weight', 'text_transformer.encoder.layer.5.attention.output.dense.bias', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.intermediate.dense.weight', 'text_transformer.encoder.layer.5.intermediate.dense.bias', 'text_transformer.encoder.layer.5.output.dense.weight', 'text_transformer.encoder.layer.5.output.dense.bias', 'text_transformer.encoder.layer.5.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.alpha_t2i', 'text_transformer.encoder.layer.6.attention.self.query.weight', 'text_transformer.encoder.layer.6.attention.self.query.bias', 'text_transformer.encoder.layer.6.attention.self.key.weight', 'text_transformer.encoder.layer.6.attention.self.key.bias', 'text_transformer.encoder.layer.6.attention.self.value.weight', 'text_transformer.encoder.layer.6.attention.self.value.bias', 'text_transformer.encoder.layer.6.attention.output.dense.weight', 'text_transformer.encoder.layer.6.attention.output.dense.bias', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.intermediate.dense.weight', 'text_transformer.encoder.layer.6.intermediate.dense.bias', 'text_transformer.encoder.layer.6.output.dense.weight', 'text_transformer.encoder.layer.6.output.dense.bias', 'text_transformer.encoder.layer.6.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.alpha_t2i', 'text_transformer.encoder.layer.7.attention.self.query.weight', 'text_transformer.encoder.layer.7.attention.self.query.bias', 'text_transformer.encoder.layer.7.attention.self.key.weight', 'text_transformer.encoder.layer.7.attention.self.key.bias', 'text_transformer.encoder.layer.7.attention.self.value.weight', 'text_transformer.encoder.layer.7.attention.self.value.bias', 'text_transformer.encoder.layer.7.attention.output.dense.weight', 'text_transformer.encoder.layer.7.attention.output.dense.bias', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.intermediate.dense.weight', 'text_transformer.encoder.layer.7.intermediate.dense.bias', 'text_transformer.encoder.layer.7.output.dense.weight', 'text_transformer.encoder.layer.7.output.dense.bias', 'text_transformer.encoder.layer.7.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.alpha_t2i', 'text_transformer.encoder.layer.8.attention.self.query.weight', 'text_transformer.encoder.layer.8.attention.self.query.bias', 'text_transformer.encoder.layer.8.attention.self.key.weight', 'text_transformer.encoder.layer.8.attention.self.key.bias', 'text_transformer.encoder.layer.8.attention.self.value.weight', 'text_transformer.encoder.layer.8.attention.self.value.bias', 'text_transformer.encoder.layer.8.attention.output.dense.weight', 'text_transformer.encoder.layer.8.attention.output.dense.bias', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.intermediate.dense.weight', 'text_transformer.encoder.layer.8.intermediate.dense.bias', 'text_transformer.encoder.layer.8.output.dense.weight', 'text_transformer.encoder.layer.8.output.dense.bias', 'text_transformer.encoder.layer.8.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.alpha_t2i', 'text_transformer.encoder.layer.9.attention.self.query.weight', 'text_transformer.encoder.layer.9.attention.self.query.bias', 'text_transformer.encoder.layer.9.attention.self.key.weight', 'text_transformer.encoder.layer.9.attention.self.key.bias', 'text_transformer.encoder.layer.9.attention.self.value.weight', 'text_transformer.encoder.layer.9.attention.self.value.bias', 'text_transformer.encoder.layer.9.attention.output.dense.weight', 'text_transformer.encoder.layer.9.attention.output.dense.bias', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.intermediate.dense.weight', 'text_transformer.encoder.layer.9.intermediate.dense.bias', 'text_transformer.encoder.layer.9.output.dense.weight', 'text_transformer.encoder.layer.9.output.dense.bias', 'text_transformer.encoder.layer.9.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.alpha_t2i', 'text_transformer.encoder.layer.10.attention.self.query.weight', 'text_transformer.encoder.layer.10.attention.self.query.bias', 'text_transformer.encoder.layer.10.attention.self.key.weight', 'text_transformer.encoder.layer.10.attention.self.key.bias', 'text_transformer.encoder.layer.10.attention.self.value.weight', 'text_transformer.encoder.layer.10.attention.self.value.bias', 'text_transformer.encoder.layer.10.attention.output.dense.weight', 'text_transformer.encoder.layer.10.attention.output.dense.bias', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.intermediate.dense.weight', 'text_transformer.encoder.layer.10.intermediate.dense.bias', 'text_transformer.encoder.layer.10.output.dense.weight', 'text_transformer.encoder.layer.10.output.dense.bias', 'text_transformer.encoder.layer.10.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.alpha_t2i', 'text_transformer.encoder.layer.11.attention.self.query.weight', 'text_transformer.encoder.layer.11.attention.self.query.bias', 'text_transformer.encoder.layer.11.attention.self.key.weight', 'text_transformer.encoder.layer.11.attention.self.key.bias', 'text_transformer.encoder.layer.11.attention.self.value.weight', 'text_transformer.encoder.layer.11.attention.self.value.bias', 'text_transformer.encoder.layer.11.attention.output.dense.weight', 'text_transformer.encoder.layer.11.attention.output.dense.bias', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.intermediate.dense.weight', 'text_transformer.encoder.layer.11.intermediate.dense.bias', 'text_transformer.encoder.layer.11.output.dense.weight', 'text_transformer.encoder.layer.11.output.dense.bias', 'text_transformer.encoder.layer.11.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.output.LayerNorm.bias', 'text_transformer.pooler.dense.weight', 'text_transformer.pooler.dense.bias', 'cross_modal_image_pooler.dense.weight', 'cross_modal_image_pooler.dense.bias', 'cross_modal_text_pooler.dense.weight', 'cross_modal_text_pooler.dense.bias', 'cross_modal_image_pooler_itc.dense.weight', 'cross_modal_image_pooler_itc.dense.bias', 'cross_modal_text_pooler_itc.dense.weight', 'cross_modal_text_pooler_itc.dense.bias', 'vqa_classifier.model.0.weight', 'vqa_classifier.model.0.bias', 'vqa_classifier.model.1.weight', 'vqa_classifier.model.1.bias', 'vqa_classifier.model.3.weight', 'vqa_classifier.model.3.bias'])
image_state_dict.keys(): odict_keys(['cross_modal_text_transform.weight', 'cross_modal_text_transform.bias', 'cross_modal_image_transform.weight', 'cross_modal_image_transform.bias', 'cross_modal_text_transform_itc.weight', 'cross_modal_text_transform_itc.bias', 'cross_modal_image_transform_itc.weight', 'cross_modal_image_transform_itc.bias', 'vit_model.patch_embed.proj.weight', 'vit_model.patch_embed.proj.bias', 'vit_model.patch_embed.norm.weight', 'vit_model.patch_embed.norm.bias', 'vit_model.layers.0.blocks.0.norm1.weight', 'vit_model.layers.0.blocks.0.norm1.bias', 'vit_model.layers.0.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.0.attn.relative_position_index', 'vit_model.layers.0.blocks.0.attn.qkv.weight', 'vit_model.layers.0.blocks.0.attn.qkv.bias', 'vit_model.layers.0.blocks.0.attn.proj.weight', 'vit_model.layers.0.blocks.0.attn.proj.bias', 'vit_model.layers.0.blocks.0.norm2.weight', 'vit_model.layers.0.blocks.0.norm2.bias', 'vit_model.layers.0.blocks.0.mlp.fc1.weight', 'vit_model.layers.0.blocks.0.mlp.fc1.bias', 'vit_model.layers.0.blocks.0.mlp.fc2.weight', 'vit_model.layers.0.blocks.0.mlp.fc2.bias', 'vit_model.layers.0.blocks.1.attn_mask', 'vit_model.layers.0.blocks.1.norm1.weight', 'vit_model.layers.0.blocks.1.norm1.bias', 'vit_model.layers.0.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.1.attn.relative_position_index', 'vit_model.layers.0.blocks.1.attn.qkv.weight', 'vit_model.layers.0.blocks.1.attn.qkv.bias', 'vit_model.layers.0.blocks.1.attn.proj.weight', 'vit_model.layers.0.blocks.1.attn.proj.bias', 'vit_model.layers.0.blocks.1.norm2.weight', 'vit_model.layers.0.blocks.1.norm2.bias', 'vit_model.layers.0.blocks.1.mlp.fc1.weight', 'vit_model.layers.0.blocks.1.mlp.fc1.bias', 'vit_model.layers.0.blocks.1.mlp.fc2.weight', 'vit_model.layers.0.blocks.1.mlp.fc2.bias', 'vit_model.layers.0.downsample.reduction.weight', 'vit_model.layers.0.downsample.norm.weight', 'vit_model.layers.0.downsample.norm.bias', 'vit_model.layers.1.blocks.0.norm1.weight', 'vit_model.layers.1.blocks.0.norm1.bias', 'vit_model.layers.1.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.0.attn.relative_position_index', 'vit_model.layers.1.blocks.0.attn.qkv.weight', 'vit_model.layers.1.blocks.0.attn.qkv.bias', 'vit_model.layers.1.blocks.0.attn.proj.weight', 'vit_model.layers.1.blocks.0.attn.proj.bias', 'vit_model.layers.1.blocks.0.norm2.weight', 'vit_model.layers.1.blocks.0.norm2.bias', 'vit_model.layers.1.blocks.0.mlp.fc1.weight', 'vit_model.layers.1.blocks.0.mlp.fc1.bias', 'vit_model.layers.1.blocks.0.mlp.fc2.weight', 'vit_model.layers.1.blocks.0.mlp.fc2.bias', 'vit_model.layers.1.blocks.1.attn_mask', 'vit_model.layers.1.blocks.1.norm1.weight', 'vit_model.layers.1.blocks.1.norm1.bias', 'vit_model.layers.1.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.1.attn.relative_position_index', 'vit_model.layers.1.blocks.1.attn.qkv.weight', 'vit_model.layers.1.blocks.1.attn.qkv.bias', 'vit_model.layers.1.blocks.1.attn.proj.weight', 'vit_model.layers.1.blocks.1.attn.proj.bias', 'vit_model.layers.1.blocks.1.norm2.weight', 'vit_model.layers.1.blocks.1.norm2.bias', 'vit_model.layers.1.blocks.1.mlp.fc1.weight', 'vit_model.layers.1.blocks.1.mlp.fc1.bias', 'vit_model.layers.1.blocks.1.mlp.fc2.weight', 'vit_model.layers.1.blocks.1.mlp.fc2.bias', 'vit_model.layers.1.downsample.reduction.weight', 'vit_model.layers.1.downsample.norm.weight', 'vit_model.layers.1.downsample.norm.bias', 'vit_model.layers.2.blocks.0.norm1.weight', 'vit_model.layers.2.blocks.0.norm1.bias', 'vit_model.layers.2.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.0.attn.relative_position_index', 'vit_model.layers.2.blocks.0.attn.qkv.weight', 'vit_model.layers.2.blocks.0.attn.qkv.bias', 'vit_model.layers.2.blocks.0.attn.proj.weight', 'vit_model.layers.2.blocks.0.attn.proj.bias', 'vit_model.layers.2.blocks.0.norm2.weight', 'vit_model.layers.2.blocks.0.norm2.bias', 'vit_model.layers.2.blocks.0.mlp.fc1.weight', 'vit_model.layers.2.blocks.0.mlp.fc1.bias', 'vit_model.layers.2.blocks.0.mlp.fc2.weight', 'vit_model.layers.2.blocks.0.mlp.fc2.bias', 'vit_model.layers.2.blocks.1.attn_mask', 'vit_model.layers.2.blocks.1.norm1.weight', 'vit_model.layers.2.blocks.1.norm1.bias', 'vit_model.layers.2.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.1.attn.relative_position_index', 'vit_model.layers.2.blocks.1.attn.qkv.weight', 'vit_model.layers.2.blocks.1.attn.qkv.bias', 'vit_model.layers.2.blocks.1.attn.proj.weight', 'vit_model.layers.2.blocks.1.attn.proj.bias', 'vit_model.layers.2.blocks.1.norm2.weight', 'vit_model.layers.2.blocks.1.norm2.bias', 'vit_model.layers.2.blocks.1.mlp.fc1.weight', 'vit_model.layers.2.blocks.1.mlp.fc1.bias', 'vit_model.layers.2.blocks.1.mlp.fc2.weight', 'vit_model.layers.2.blocks.1.mlp.fc2.bias', 'vit_model.layers.2.blocks.2.norm1.weight', 'vit_model.layers.2.blocks.2.norm1.bias', 'vit_model.layers.2.blocks.2.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.2.attn.relative_position_index', 'vit_model.layers.2.blocks.2.attn.qkv.weight', 'vit_model.layers.2.blocks.2.attn.qkv.bias', 'vit_model.layers.2.blocks.2.attn.proj.weight', 'vit_model.layers.2.blocks.2.attn.proj.bias', 'vit_model.layers.2.blocks.2.norm2.weight', 'vit_model.layers.2.blocks.2.norm2.bias', 'vit_model.layers.2.blocks.2.mlp.fc1.weight', 'vit_model.layers.2.blocks.2.mlp.fc1.bias', 'vit_model.layers.2.blocks.2.mlp.fc2.weight', 'vit_model.layers.2.blocks.2.mlp.fc2.bias', 'vit_model.layers.2.blocks.3.attn_mask', 'vit_model.layers.2.blocks.3.norm1.weight', 'vit_model.layers.2.blocks.3.norm1.bias', 'vit_model.layers.2.blocks.3.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.3.attn.relative_position_index', 'vit_model.layers.2.blocks.3.attn.qkv.weight', 'vit_model.layers.2.blocks.3.attn.qkv.bias', 'vit_model.layers.2.blocks.3.attn.proj.weight', 'vit_model.layers.2.blocks.3.attn.proj.bias', 'vit_model.layers.2.blocks.3.norm2.weight', 'vit_model.layers.2.blocks.3.norm2.bias', 'vit_model.layers.2.blocks.3.mlp.fc1.weight', 'vit_model.layers.2.blocks.3.mlp.fc1.bias', 'vit_model.layers.2.blocks.3.mlp.fc2.weight', 'vit_model.layers.2.blocks.3.mlp.fc2.bias', 'vit_model.layers.2.blocks.4.norm1.weight', 'vit_model.layers.2.blocks.4.norm1.bias', 'vit_model.layers.2.blocks.4.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.4.attn.relative_position_index', 'vit_model.layers.2.blocks.4.attn.qkv.weight', 'vit_model.layers.2.blocks.4.attn.qkv.bias', 'vit_model.layers.2.blocks.4.attn.proj.weight', 'vit_model.layers.2.blocks.4.attn.proj.bias', 'vit_model.layers.2.blocks.4.norm2.weight', 'vit_model.layers.2.blocks.4.norm2.bias', 'vit_model.layers.2.blocks.4.mlp.fc1.weight', 'vit_model.layers.2.blocks.4.mlp.fc1.bias', 'vit_model.layers.2.blocks.4.mlp.fc2.weight', 'vit_model.layers.2.blocks.4.mlp.fc2.bias', 'vit_model.layers.2.blocks.5.attn_mask', 'vit_model.layers.2.blocks.5.norm1.weight', 'vit_model.layers.2.blocks.5.norm1.bias', 'vit_model.layers.2.blocks.5.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.5.attn.relative_position_index', 'vit_model.layers.2.blocks.5.attn.qkv.weight', 'vit_model.layers.2.blocks.5.attn.qkv.bias', 'vit_model.layers.2.blocks.5.attn.proj.weight', 'vit_model.layers.2.blocks.5.attn.proj.bias', 'vit_model.layers.2.blocks.5.norm2.weight', 'vit_model.layers.2.blocks.5.norm2.bias', 'vit_model.layers.2.blocks.5.mlp.fc1.weight', 'vit_model.layers.2.blocks.5.mlp.fc1.bias', 'vit_model.layers.2.blocks.5.mlp.fc2.weight', 'vit_model.layers.2.blocks.5.mlp.fc2.bias', 'vit_model.layers.2.blocks.6.norm1.weight', 'vit_model.layers.2.blocks.6.norm1.bias', 'vit_model.layers.2.blocks.6.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.6.attn.relative_position_index', 'vit_model.layers.2.blocks.6.attn.qkv.weight', 'vit_model.layers.2.blocks.6.attn.qkv.bias', 'vit_model.layers.2.blocks.6.attn.proj.weight', 'vit_model.layers.2.blocks.6.attn.proj.bias', 'vit_model.layers.2.blocks.6.norm2.weight', 'vit_model.layers.2.blocks.6.norm2.bias', 'vit_model.layers.2.blocks.6.mlp.fc1.weight', 'vit_model.layers.2.blocks.6.mlp.fc1.bias', 'vit_model.layers.2.blocks.6.mlp.fc2.weight', 'vit_model.layers.2.blocks.6.mlp.fc2.bias', 'vit_model.layers.2.blocks.7.attn_mask', 'vit_model.layers.2.blocks.7.norm1.weight', 'vit_model.layers.2.blocks.7.norm1.bias', 'vit_model.layers.2.blocks.7.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.7.attn.relative_position_index', 'vit_model.layers.2.blocks.7.attn.qkv.weight', 'vit_model.layers.2.blocks.7.attn.qkv.bias', 'vit_model.layers.2.blocks.7.attn.proj.weight', 'vit_model.layers.2.blocks.7.attn.proj.bias', 'vit_model.layers.2.blocks.7.norm2.weight', 'vit_model.layers.2.blocks.7.norm2.bias', 'vit_model.layers.2.blocks.7.mlp.fc1.weight', 'vit_model.layers.2.blocks.7.mlp.fc1.bias', 'vit_model.layers.2.blocks.7.mlp.fc2.weight', 'vit_model.layers.2.blocks.7.mlp.fc2.bias', 'vit_model.layers.2.blocks.8.norm1.weight', 'vit_model.layers.2.blocks.8.norm1.bias', 'vit_model.layers.2.blocks.8.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.8.attn.relative_position_index', 'vit_model.layers.2.blocks.8.attn.qkv.weight', 'vit_model.layers.2.blocks.8.attn.qkv.bias', 'vit_model.layers.2.blocks.8.attn.proj.weight', 'vit_model.layers.2.blocks.8.attn.proj.bias', 'vit_model.layers.2.blocks.8.norm2.weight', 'vit_model.layers.2.blocks.8.norm2.bias', 'vit_model.layers.2.blocks.8.mlp.fc1.weight', 'vit_model.layers.2.blocks.8.mlp.fc1.bias', 'vit_model.layers.2.blocks.8.mlp.fc2.weight', 'vit_model.layers.2.blocks.8.mlp.fc2.bias', 'vit_model.layers.2.blocks.9.attn_mask', 'vit_model.layers.2.blocks.9.norm1.weight', 'vit_model.layers.2.blocks.9.norm1.bias', 'vit_model.layers.2.blocks.9.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.9.attn.relative_position_index', 'vit_model.layers.2.blocks.9.attn.qkv.weight', 'vit_model.layers.2.blocks.9.attn.qkv.bias', 'vit_model.layers.2.blocks.9.attn.proj.weight', 'vit_model.layers.2.blocks.9.attn.proj.bias', 'vit_model.layers.2.blocks.9.norm2.weight', 'vit_model.layers.2.blocks.9.norm2.bias', 'vit_model.layers.2.blocks.9.mlp.fc1.weight', 'vit_model.layers.2.blocks.9.mlp.fc1.bias', 'vit_model.layers.2.blocks.9.mlp.fc2.weight', 'vit_model.layers.2.blocks.9.mlp.fc2.bias', 'vit_model.layers.2.blocks.10.norm1.weight', 'vit_model.layers.2.blocks.10.norm1.bias', 'vit_model.layers.2.blocks.10.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.10.attn.relative_position_index', 'vit_model.layers.2.blocks.10.attn.qkv.weight', 'vit_model.layers.2.blocks.10.attn.qkv.bias', 'vit_model.layers.2.blocks.10.attn.proj.weight', 'vit_model.layers.2.blocks.10.attn.proj.bias', 'vit_model.layers.2.blocks.10.norm2.weight', 'vit_model.layers.2.blocks.10.norm2.bias', 'vit_model.layers.2.blocks.10.mlp.fc1.weight', 'vit_model.layers.2.blocks.10.mlp.fc1.bias', 'vit_model.layers.2.blocks.10.mlp.fc2.weight', 'vit_model.layers.2.blocks.10.mlp.fc2.bias', 'vit_model.layers.2.blocks.11.attn_mask', 'vit_model.layers.2.blocks.11.norm1.weight', 'vit_model.layers.2.blocks.11.norm1.bias', 'vit_model.layers.2.blocks.11.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.11.attn.relative_position_index', 'vit_model.layers.2.blocks.11.attn.qkv.weight', 'vit_model.layers.2.blocks.11.attn.qkv.bias', 'vit_model.layers.2.blocks.11.attn.proj.weight', 'vit_model.layers.2.blocks.11.attn.proj.bias', 'vit_model.layers.2.blocks.11.norm2.weight', 'vit_model.layers.2.blocks.11.norm2.bias', 'vit_model.layers.2.blocks.11.mlp.fc1.weight', 'vit_model.layers.2.blocks.11.mlp.fc1.bias', 'vit_model.layers.2.blocks.11.mlp.fc2.weight', 'vit_model.layers.2.blocks.11.mlp.fc2.bias', 'vit_model.layers.2.blocks.12.norm1.weight', 'vit_model.layers.2.blocks.12.norm1.bias', 'vit_model.layers.2.blocks.12.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.12.attn.relative_position_index', 'vit_model.layers.2.blocks.12.attn.qkv.weight', 'vit_model.layers.2.blocks.12.attn.qkv.bias', 'vit_model.layers.2.blocks.12.attn.proj.weight', 'vit_model.layers.2.blocks.12.attn.proj.bias', 'vit_model.layers.2.blocks.12.norm2.weight', 'vit_model.layers.2.blocks.12.norm2.bias', 'vit_model.layers.2.blocks.12.mlp.fc1.weight', 'vit_model.layers.2.blocks.12.mlp.fc1.bias', 'vit_model.layers.2.blocks.12.mlp.fc2.weight', 'vit_model.layers.2.blocks.12.mlp.fc2.bias', 'vit_model.layers.2.blocks.13.attn_mask', 'vit_model.layers.2.blocks.13.norm1.weight', 'vit_model.layers.2.blocks.13.norm1.bias', 'vit_model.layers.2.blocks.13.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.13.attn.relative_position_index', 'vit_model.layers.2.blocks.13.attn.qkv.weight', 'vit_model.layers.2.blocks.13.attn.qkv.bias', 'vit_model.layers.2.blocks.13.attn.proj.weight', 'vit_model.layers.2.blocks.13.attn.proj.bias', 'vit_model.layers.2.blocks.13.norm2.weight', 'vit_model.layers.2.blocks.13.norm2.bias', 'vit_model.layers.2.blocks.13.mlp.fc1.weight', 'vit_model.layers.2.blocks.13.mlp.fc1.bias', 'vit_model.layers.2.blocks.13.mlp.fc2.weight', 'vit_model.layers.2.blocks.13.mlp.fc2.bias', 'vit_model.layers.2.blocks.14.norm1.weight', 'vit_model.layers.2.blocks.14.norm1.bias', 'vit_model.layers.2.blocks.14.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.14.attn.alpha_i2t', 'vit_model.layers.2.blocks.14.attn.relative_position_index', 'vit_model.layers.2.blocks.14.attn.qkv.weight', 'vit_model.layers.2.blocks.14.attn.qkv.bias', 'vit_model.layers.2.blocks.14.attn.proj.weight', 'vit_model.layers.2.blocks.14.attn.proj.bias', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.14.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.14.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.14.norm2.weight', 'vit_model.layers.2.blocks.14.norm2.bias', 'vit_model.layers.2.blocks.14.mlp.fc1.weight', 'vit_model.layers.2.blocks.14.mlp.fc1.bias', 'vit_model.layers.2.blocks.14.mlp.fc2.weight', 'vit_model.layers.2.blocks.14.mlp.fc2.bias', 'vit_model.layers.2.blocks.15.attn_mask', 'vit_model.layers.2.blocks.15.norm1.weight', 'vit_model.layers.2.blocks.15.norm1.bias', 'vit_model.layers.2.blocks.15.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.15.attn.alpha_i2t', 'vit_model.layers.2.blocks.15.attn.relative_position_index', 'vit_model.layers.2.blocks.15.attn.qkv.weight', 'vit_model.layers.2.blocks.15.attn.qkv.bias', 'vit_model.layers.2.blocks.15.attn.proj.weight', 'vit_model.layers.2.blocks.15.attn.proj.bias', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.15.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.15.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.15.norm2.weight', 'vit_model.layers.2.blocks.15.norm2.bias', 'vit_model.layers.2.blocks.15.mlp.fc1.weight', 'vit_model.layers.2.blocks.15.mlp.fc1.bias', 'vit_model.layers.2.blocks.15.mlp.fc2.weight', 'vit_model.layers.2.blocks.15.mlp.fc2.bias', 'vit_model.layers.2.blocks.16.norm1.weight', 'vit_model.layers.2.blocks.16.norm1.bias', 'vit_model.layers.2.blocks.16.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.16.attn.alpha_i2t', 'vit_model.layers.2.blocks.16.attn.relative_position_index', 'vit_model.layers.2.blocks.16.attn.qkv.weight', 'vit_model.layers.2.blocks.16.attn.qkv.bias', 'vit_model.layers.2.blocks.16.attn.proj.weight', 'vit_model.layers.2.blocks.16.attn.proj.bias', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.16.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.16.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.16.norm2.weight', 'vit_model.layers.2.blocks.16.norm2.bias', 'vit_model.layers.2.blocks.16.mlp.fc1.weight', 'vit_model.layers.2.blocks.16.mlp.fc1.bias', 'vit_model.layers.2.blocks.16.mlp.fc2.weight', 'vit_model.layers.2.blocks.16.mlp.fc2.bias', 'vit_model.layers.2.blocks.17.attn_mask', 'vit_model.layers.2.blocks.17.norm1.weight', 'vit_model.layers.2.blocks.17.norm1.bias', 'vit_model.layers.2.blocks.17.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.17.attn.alpha_i2t', 'vit_model.layers.2.blocks.17.attn.relative_position_index', 'vit_model.layers.2.blocks.17.attn.qkv.weight', 'vit_model.layers.2.blocks.17.attn.qkv.bias', 'vit_model.layers.2.blocks.17.attn.proj.weight', 'vit_model.layers.2.blocks.17.attn.proj.bias', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.17.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.17.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.17.norm2.weight', 'vit_model.layers.2.blocks.17.norm2.bias', 'vit_model.layers.2.blocks.17.mlp.fc1.weight', 'vit_model.layers.2.blocks.17.mlp.fc1.bias', 'vit_model.layers.2.blocks.17.mlp.fc2.weight', 'vit_model.layers.2.blocks.17.mlp.fc2.bias', 'vit_model.layers.2.downsample.reduction.weight', 'vit_model.layers.2.downsample.norm.weight', 'vit_model.layers.2.downsample.norm.bias', 'vit_model.layers.3.blocks.0.norm1.weight', 'vit_model.layers.3.blocks.0.norm1.bias', 'vit_model.layers.3.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.0.attn.alpha_i2t', 'vit_model.layers.3.blocks.0.attn.relative_position_index', 'vit_model.layers.3.blocks.0.attn.qkv.weight', 'vit_model.layers.3.blocks.0.attn.qkv.bias', 'vit_model.layers.3.blocks.0.attn.proj.weight', 'vit_model.layers.3.blocks.0.attn.proj.bias', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.0.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.0.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.0.norm2.weight', 'vit_model.layers.3.blocks.0.norm2.bias', 'vit_model.layers.3.blocks.0.mlp.fc1.weight', 'vit_model.layers.3.blocks.0.mlp.fc1.bias', 'vit_model.layers.3.blocks.0.mlp.fc2.weight', 'vit_model.layers.3.blocks.0.mlp.fc2.bias', 'vit_model.layers.3.blocks.1.norm1.weight', 'vit_model.layers.3.blocks.1.norm1.bias', 'vit_model.layers.3.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.1.attn.alpha_i2t', 'vit_model.layers.3.blocks.1.attn.relative_position_index', 'vit_model.layers.3.blocks.1.attn.qkv.weight', 'vit_model.layers.3.blocks.1.attn.qkv.bias', 'vit_model.layers.3.blocks.1.attn.proj.weight', 'vit_model.layers.3.blocks.1.attn.proj.bias', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.1.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.1.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.1.norm2.weight', 'vit_model.layers.3.blocks.1.norm2.bias', 'vit_model.layers.3.blocks.1.mlp.fc1.weight', 'vit_model.layers.3.blocks.1.mlp.fc1.bias', 'vit_model.layers.3.blocks.1.mlp.fc2.weight', 'vit_model.layers.3.blocks.1.mlp.fc2.bias', 'vit_model.norm.weight', 'vit_model.norm.bias', 'text_transformer.embeddings.position_ids', 'text_transformer.embeddings.word_embeddings.weight', 'text_transformer.embeddings.position_embeddings.weight', 'text_transformer.embeddings.token_type_embeddings.weight', 'text_transformer.embeddings.LayerNorm.weight', 'text_transformer.embeddings.LayerNorm.bias', 'text_transformer.encoder.layer.0.alpha_t2i', 'text_transformer.encoder.layer.0.attention.self.query.weight', 'text_transformer.encoder.layer.0.attention.self.query.bias', 'text_transformer.encoder.layer.0.attention.self.key.weight', 'text_transformer.encoder.layer.0.attention.self.key.bias', 'text_transformer.encoder.layer.0.attention.self.value.weight', 'text_transformer.encoder.layer.0.attention.self.value.bias', 'text_transformer.encoder.layer.0.attention.output.dense.weight', 'text_transformer.encoder.layer.0.attention.output.dense.bias', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.0.intermediate.dense.weight', 'text_transformer.encoder.layer.0.intermediate.dense.bias', 'text_transformer.encoder.layer.0.output.dense.weight', 'text_transformer.encoder.layer.0.output.dense.bias', 'text_transformer.encoder.layer.0.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.alpha_t2i', 'text_transformer.encoder.layer.1.attention.self.query.weight', 'text_transformer.encoder.layer.1.attention.self.query.bias', 'text_transformer.encoder.layer.1.attention.self.key.weight', 'text_transformer.encoder.layer.1.attention.self.key.bias', 'text_transformer.encoder.layer.1.attention.self.value.weight', 'text_transformer.encoder.layer.1.attention.self.value.bias', 'text_transformer.encoder.layer.1.attention.output.dense.weight', 'text_transformer.encoder.layer.1.attention.output.dense.bias', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.intermediate.dense.weight', 'text_transformer.encoder.layer.1.intermediate.dense.bias', 'text_transformer.encoder.layer.1.output.dense.weight', 'text_transformer.encoder.layer.1.output.dense.bias', 'text_transformer.encoder.layer.1.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.alpha_t2i', 'text_transformer.encoder.layer.2.attention.self.query.weight', 'text_transformer.encoder.layer.2.attention.self.query.bias', 'text_transformer.encoder.layer.2.attention.self.key.weight', 'text_transformer.encoder.layer.2.attention.self.key.bias', 'text_transformer.encoder.layer.2.attention.self.value.weight', 'text_transformer.encoder.layer.2.attention.self.value.bias', 'text_transformer.encoder.layer.2.attention.output.dense.weight', 'text_transformer.encoder.layer.2.attention.output.dense.bias', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.intermediate.dense.weight', 'text_transformer.encoder.layer.2.intermediate.dense.bias', 'text_transformer.encoder.layer.2.output.dense.weight', 'text_transformer.encoder.layer.2.output.dense.bias', 'text_transformer.encoder.layer.2.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.alpha_t2i', 'text_transformer.encoder.layer.3.attention.self.query.weight', 'text_transformer.encoder.layer.3.attention.self.query.bias', 'text_transformer.encoder.layer.3.attention.self.key.weight', 'text_transformer.encoder.layer.3.attention.self.key.bias', 'text_transformer.encoder.layer.3.attention.self.value.weight', 'text_transformer.encoder.layer.3.attention.self.value.bias', 'text_transformer.encoder.layer.3.attention.output.dense.weight', 'text_transformer.encoder.layer.3.attention.output.dense.bias', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.intermediate.dense.weight', 'text_transformer.encoder.layer.3.intermediate.dense.bias', 'text_transformer.encoder.layer.3.output.dense.weight', 'text_transformer.encoder.layer.3.output.dense.bias', 'text_transformer.encoder.layer.3.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.alpha_t2i', 'text_transformer.encoder.layer.4.attention.self.query.weight', 'text_transformer.encoder.layer.4.attention.self.query.bias', 'text_transformer.encoder.layer.4.attention.self.key.weight', 'text_transformer.encoder.layer.4.attention.self.key.bias', 'text_transformer.encoder.layer.4.attention.self.value.weight', 'text_transformer.encoder.layer.4.attention.self.value.bias', 'text_transformer.encoder.layer.4.attention.output.dense.weight', 'text_transformer.encoder.layer.4.attention.output.dense.bias', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.intermediate.dense.weight', 'text_transformer.encoder.layer.4.intermediate.dense.bias', 'text_transformer.encoder.layer.4.output.dense.weight', 'text_transformer.encoder.layer.4.output.dense.bias', 'text_transformer.encoder.layer.4.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.alpha_t2i', 'text_transformer.encoder.layer.5.attention.self.query.weight', 'text_transformer.encoder.layer.5.attention.self.query.bias', 'text_transformer.encoder.layer.5.attention.self.key.weight', 'text_transformer.encoder.layer.5.attention.self.key.bias', 'text_transformer.encoder.layer.5.attention.self.value.weight', 'text_transformer.encoder.layer.5.attention.self.value.bias', 'text_transformer.encoder.layer.5.attention.output.dense.weight', 'text_transformer.encoder.layer.5.attention.output.dense.bias', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.intermediate.dense.weight', 'text_transformer.encoder.layer.5.intermediate.dense.bias', 'text_transformer.encoder.layer.5.output.dense.weight', 'text_transformer.encoder.layer.5.output.dense.bias', 'text_transformer.encoder.layer.5.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.alpha_t2i', 'text_transformer.encoder.layer.6.attention.self.query.weight', 'text_transformer.encoder.layer.6.attention.self.query.bias', 'text_transformer.encoder.layer.6.attention.self.key.weight', 'text_transformer.encoder.layer.6.attention.self.key.bias', 'text_transformer.encoder.layer.6.attention.self.value.weight', 'text_transformer.encoder.layer.6.attention.self.value.bias', 'text_transformer.encoder.layer.6.attention.output.dense.weight', 'text_transformer.encoder.layer.6.attention.output.dense.bias', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.intermediate.dense.weight', 'text_transformer.encoder.layer.6.intermediate.dense.bias', 'text_transformer.encoder.layer.6.output.dense.weight', 'text_transformer.encoder.layer.6.output.dense.bias', 'text_transformer.encoder.layer.6.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.alpha_t2i', 'text_transformer.encoder.layer.7.attention.self.query.weight', 'text_transformer.encoder.layer.7.attention.self.query.bias', 'text_transformer.encoder.layer.7.attention.self.key.weight', 'text_transformer.encoder.layer.7.attention.self.key.bias', 'text_transformer.encoder.layer.7.attention.self.value.weight', 'text_transformer.encoder.layer.7.attention.self.value.bias', 'text_transformer.encoder.layer.7.attention.output.dense.weight', 'text_transformer.encoder.layer.7.attention.output.dense.bias', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.intermediate.dense.weight', 'text_transformer.encoder.layer.7.intermediate.dense.bias', 'text_transformer.encoder.layer.7.output.dense.weight', 'text_transformer.encoder.layer.7.output.dense.bias', 'text_transformer.encoder.layer.7.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.alpha_t2i', 'text_transformer.encoder.layer.8.attention.self.query.weight', 'text_transformer.encoder.layer.8.attention.self.query.bias', 'text_transformer.encoder.layer.8.attention.self.key.weight', 'text_transformer.encoder.layer.8.attention.self.key.bias', 'text_transformer.encoder.layer.8.attention.self.value.weight', 'text_transformer.encoder.layer.8.attention.self.value.bias', 'text_transformer.encoder.layer.8.attention.output.dense.weight', 'text_transformer.encoder.layer.8.attention.output.dense.bias', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.intermediate.dense.weight', 'text_transformer.encoder.layer.8.intermediate.dense.bias', 'text_transformer.encoder.layer.8.output.dense.weight', 'text_transformer.encoder.layer.8.output.dense.bias', 'text_transformer.encoder.layer.8.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.alpha_t2i', 'text_transformer.encoder.layer.9.attention.self.query.weight', 'text_transformer.encoder.layer.9.attention.self.query.bias', 'text_transformer.encoder.layer.9.attention.self.key.weight', 'text_transformer.encoder.layer.9.attention.self.key.bias', 'text_transformer.encoder.layer.9.attention.self.value.weight', 'text_transformer.encoder.layer.9.attention.self.value.bias', 'text_transformer.encoder.layer.9.attention.output.dense.weight', 'text_transformer.encoder.layer.9.attention.output.dense.bias', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.intermediate.dense.weight', 'text_transformer.encoder.layer.9.intermediate.dense.bias', 'text_transformer.encoder.layer.9.output.dense.weight', 'text_transformer.encoder.layer.9.output.dense.bias', 'text_transformer.encoder.layer.9.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.alpha_t2i', 'text_transformer.encoder.layer.10.attention.self.query.weight', 'text_transformer.encoder.layer.10.attention.self.query.bias', 'text_transformer.encoder.layer.10.attention.self.key.weight', 'text_transformer.encoder.layer.10.attention.self.key.bias', 'text_transformer.encoder.layer.10.attention.self.value.weight', 'text_transformer.encoder.layer.10.attention.self.value.bias', 'text_transformer.encoder.layer.10.attention.output.dense.weight', 'text_transformer.encoder.layer.10.attention.output.dense.bias', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.intermediate.dense.weight', 'text_transformer.encoder.layer.10.intermediate.dense.bias', 'text_transformer.encoder.layer.10.output.dense.weight', 'text_transformer.encoder.layer.10.output.dense.bias', 'text_transformer.encoder.layer.10.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.alpha_t2i', 'text_transformer.encoder.layer.11.attention.self.query.weight', 'text_transformer.encoder.layer.11.attention.self.query.bias', 'text_transformer.encoder.layer.11.attention.self.key.weight', 'text_transformer.encoder.layer.11.attention.self.key.bias', 'text_transformer.encoder.layer.11.attention.self.value.weight', 'text_transformer.encoder.layer.11.attention.self.value.bias', 'text_transformer.encoder.layer.11.attention.output.dense.weight', 'text_transformer.encoder.layer.11.attention.output.dense.bias', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.intermediate.dense.weight', 'text_transformer.encoder.layer.11.intermediate.dense.bias', 'text_transformer.encoder.layer.11.output.dense.weight', 'text_transformer.encoder.layer.11.output.dense.bias', 'text_transformer.encoder.layer.11.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.output.LayerNorm.bias', 'text_transformer.pooler.dense.weight', 'text_transformer.pooler.dense.bias', 'cross_modal_image_pooler.dense.weight', 'cross_modal_image_pooler.dense.bias', 'cross_modal_text_pooler.dense.weight', 'cross_modal_text_pooler.dense.bias', 'cross_modal_image_pooler_itc.dense.weight', 'cross_modal_image_pooler_itc.dense.bias', 'cross_modal_text_pooler_itc.dense.weight', 'cross_modal_text_pooler_itc.dense.bias', 'vqa_classifier.model.0.weight', 'vqa_classifier.model.0.bias', 'vqa_classifier.model.1.weight', 'vqa_classifier.model.1.bias', 'vqa_classifier.model.3.weight', 'vqa_classifier.model.3.bias'])
image_state_dict.keys(): odict_keys(['cross_modal_text_transform.weight', 'cross_modal_text_transform.bias', 'cross_modal_image_transform.weight', 'cross_modal_image_transform.bias', 'cross_modal_text_transform_itc.weight', 'cross_modal_text_transform_itc.bias', 'cross_modal_image_transform_itc.weight', 'cross_modal_image_transform_itc.bias', 'vit_model.patch_embed.proj.weight', 'vit_model.patch_embed.proj.bias', 'vit_model.patch_embed.norm.weight', 'vit_model.patch_embed.norm.bias', 'vit_model.layers.0.blocks.0.norm1.weight', 'vit_model.layers.0.blocks.0.norm1.bias', 'vit_model.layers.0.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.0.attn.relative_position_index', 'vit_model.layers.0.blocks.0.attn.qkv.weight', 'vit_model.layers.0.blocks.0.attn.qkv.bias', 'vit_model.layers.0.blocks.0.attn.proj.weight', 'vit_model.layers.0.blocks.0.attn.proj.bias', 'vit_model.layers.0.blocks.0.norm2.weight', 'vit_model.layers.0.blocks.0.norm2.bias', 'vit_model.layers.0.blocks.0.mlp.fc1.weight', 'vit_model.layers.0.blocks.0.mlp.fc1.bias', 'vit_model.layers.0.blocks.0.mlp.fc2.weight', 'vit_model.layers.0.blocks.0.mlp.fc2.bias', 'vit_model.layers.0.blocks.1.attn_mask', 'vit_model.layers.0.blocks.1.norm1.weight', 'vit_model.layers.0.blocks.1.norm1.bias', 'vit_model.layers.0.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.0.blocks.1.attn.relative_position_index', 'vit_model.layers.0.blocks.1.attn.qkv.weight', 'vit_model.layers.0.blocks.1.attn.qkv.bias', 'vit_model.layers.0.blocks.1.attn.proj.weight', 'vit_model.layers.0.blocks.1.attn.proj.bias', 'vit_model.layers.0.blocks.1.norm2.weight', 'vit_model.layers.0.blocks.1.norm2.bias', 'vit_model.layers.0.blocks.1.mlp.fc1.weight', 'vit_model.layers.0.blocks.1.mlp.fc1.bias', 'vit_model.layers.0.blocks.1.mlp.fc2.weight', 'vit_model.layers.0.blocks.1.mlp.fc2.bias', 'vit_model.layers.0.downsample.reduction.weight', 'vit_model.layers.0.downsample.norm.weight', 'vit_model.layers.0.downsample.norm.bias', 'vit_model.layers.1.blocks.0.norm1.weight', 'vit_model.layers.1.blocks.0.norm1.bias', 'vit_model.layers.1.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.0.attn.relative_position_index', 'vit_model.layers.1.blocks.0.attn.qkv.weight', 'vit_model.layers.1.blocks.0.attn.qkv.bias', 'vit_model.layers.1.blocks.0.attn.proj.weight', 'vit_model.layers.1.blocks.0.attn.proj.bias', 'vit_model.layers.1.blocks.0.norm2.weight', 'vit_model.layers.1.blocks.0.norm2.bias', 'vit_model.layers.1.blocks.0.mlp.fc1.weight', 'vit_model.layers.1.blocks.0.mlp.fc1.bias', 'vit_model.layers.1.blocks.0.mlp.fc2.weight', 'vit_model.layers.1.blocks.0.mlp.fc2.bias', 'vit_model.layers.1.blocks.1.attn_mask', 'vit_model.layers.1.blocks.1.norm1.weight', 'vit_model.layers.1.blocks.1.norm1.bias', 'vit_model.layers.1.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.1.blocks.1.attn.relative_position_index', 'vit_model.layers.1.blocks.1.attn.qkv.weight', 'vit_model.layers.1.blocks.1.attn.qkv.bias', 'vit_model.layers.1.blocks.1.attn.proj.weight', 'vit_model.layers.1.blocks.1.attn.proj.bias', 'vit_model.layers.1.blocks.1.norm2.weight', 'vit_model.layers.1.blocks.1.norm2.bias', 'vit_model.layers.1.blocks.1.mlp.fc1.weight', 'vit_model.layers.1.blocks.1.mlp.fc1.bias', 'vit_model.layers.1.blocks.1.mlp.fc2.weight', 'vit_model.layers.1.blocks.1.mlp.fc2.bias', 'vit_model.layers.1.downsample.reduction.weight', 'vit_model.layers.1.downsample.norm.weight', 'vit_model.layers.1.downsample.norm.bias', 'vit_model.layers.2.blocks.0.norm1.weight', 'vit_model.layers.2.blocks.0.norm1.bias', 'vit_model.layers.2.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.0.attn.relative_position_index', 'vit_model.layers.2.blocks.0.attn.qkv.weight', 'vit_model.layers.2.blocks.0.attn.qkv.bias', 'vit_model.layers.2.blocks.0.attn.proj.weight', 'vit_model.layers.2.blocks.0.attn.proj.bias', 'vit_model.layers.2.blocks.0.norm2.weight', 'vit_model.layers.2.blocks.0.norm2.bias', 'vit_model.layers.2.blocks.0.mlp.fc1.weight', 'vit_model.layers.2.blocks.0.mlp.fc1.bias', 'vit_model.layers.2.blocks.0.mlp.fc2.weight', 'vit_model.layers.2.blocks.0.mlp.fc2.bias', 'vit_model.layers.2.blocks.1.attn_mask', 'vit_model.layers.2.blocks.1.norm1.weight', 'vit_model.layers.2.blocks.1.norm1.bias', 'vit_model.layers.2.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.1.attn.relative_position_index', 'vit_model.layers.2.blocks.1.attn.qkv.weight', 'vit_model.layers.2.blocks.1.attn.qkv.bias', 'vit_model.layers.2.blocks.1.attn.proj.weight', 'vit_model.layers.2.blocks.1.attn.proj.bias', 'vit_model.layers.2.blocks.1.norm2.weight', 'vit_model.layers.2.blocks.1.norm2.bias', 'vit_model.layers.2.blocks.1.mlp.fc1.weight', 'vit_model.layers.2.blocks.1.mlp.fc1.bias', 'vit_model.layers.2.blocks.1.mlp.fc2.weight', 'vit_model.layers.2.blocks.1.mlp.fc2.bias', 'vit_model.layers.2.blocks.2.norm1.weight', 'vit_model.layers.2.blocks.2.norm1.bias', 'vit_model.layers.2.blocks.2.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.2.attn.relative_position_index', 'vit_model.layers.2.blocks.2.attn.qkv.weight', 'vit_model.layers.2.blocks.2.attn.qkv.bias', 'vit_model.layers.2.blocks.2.attn.proj.weight', 'vit_model.layers.2.blocks.2.attn.proj.bias', 'vit_model.layers.2.blocks.2.norm2.weight', 'vit_model.layers.2.blocks.2.norm2.bias', 'vit_model.layers.2.blocks.2.mlp.fc1.weight', 'vit_model.layers.2.blocks.2.mlp.fc1.bias', 'vit_model.layers.2.blocks.2.mlp.fc2.weight', 'vit_model.layers.2.blocks.2.mlp.fc2.bias', 'vit_model.layers.2.blocks.3.attn_mask', 'vit_model.layers.2.blocks.3.norm1.weight', 'vit_model.layers.2.blocks.3.norm1.bias', 'vit_model.layers.2.blocks.3.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.3.attn.relative_position_index', 'vit_model.layers.2.blocks.3.attn.qkv.weight', 'vit_model.layers.2.blocks.3.attn.qkv.bias', 'vit_model.layers.2.blocks.3.attn.proj.weight', 'vit_model.layers.2.blocks.3.attn.proj.bias', 'vit_model.layers.2.blocks.3.norm2.weight', 'vit_model.layers.2.blocks.3.norm2.bias', 'vit_model.layers.2.blocks.3.mlp.fc1.weight', 'vit_model.layers.2.blocks.3.mlp.fc1.bias', 'vit_model.layers.2.blocks.3.mlp.fc2.weight', 'vit_model.layers.2.blocks.3.mlp.fc2.bias', 'vit_model.layers.2.blocks.4.norm1.weight', 'vit_model.layers.2.blocks.4.norm1.bias', 'vit_model.layers.2.blocks.4.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.4.attn.relative_position_index', 'vit_model.layers.2.blocks.4.attn.qkv.weight', 'vit_model.layers.2.blocks.4.attn.qkv.bias', 'vit_model.layers.2.blocks.4.attn.proj.weight', 'vit_model.layers.2.blocks.4.attn.proj.bias', 'vit_model.layers.2.blocks.4.norm2.weight', 'vit_model.layers.2.blocks.4.norm2.bias', 'vit_model.layers.2.blocks.4.mlp.fc1.weight', 'vit_model.layers.2.blocks.4.mlp.fc1.bias', 'vit_model.layers.2.blocks.4.mlp.fc2.weight', 'vit_model.layers.2.blocks.4.mlp.fc2.bias', 'vit_model.layers.2.blocks.5.attn_mask', 'vit_model.layers.2.blocks.5.norm1.weight', 'vit_model.layers.2.blocks.5.norm1.bias', 'vit_model.layers.2.blocks.5.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.5.attn.relative_position_index', 'vit_model.layers.2.blocks.5.attn.qkv.weight', 'vit_model.layers.2.blocks.5.attn.qkv.bias', 'vit_model.layers.2.blocks.5.attn.proj.weight', 'vit_model.layers.2.blocks.5.attn.proj.bias', 'vit_model.layers.2.blocks.5.norm2.weight', 'vit_model.layers.2.blocks.5.norm2.bias', 'vit_model.layers.2.blocks.5.mlp.fc1.weight', 'vit_model.layers.2.blocks.5.mlp.fc1.bias', 'vit_model.layers.2.blocks.5.mlp.fc2.weight', 'vit_model.layers.2.blocks.5.mlp.fc2.bias', 'vit_model.layers.2.blocks.6.norm1.weight', 'vit_model.layers.2.blocks.6.norm1.bias', 'vit_model.layers.2.blocks.6.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.6.attn.relative_position_index', 'vit_model.layers.2.blocks.6.attn.qkv.weight', 'vit_model.layers.2.blocks.6.attn.qkv.bias', 'vit_model.layers.2.blocks.6.attn.proj.weight', 'vit_model.layers.2.blocks.6.attn.proj.bias', 'vit_model.layers.2.blocks.6.norm2.weight', 'vit_model.layers.2.blocks.6.norm2.bias', 'vit_model.layers.2.blocks.6.mlp.fc1.weight', 'vit_model.layers.2.blocks.6.mlp.fc1.bias', 'vit_model.layers.2.blocks.6.mlp.fc2.weight', 'vit_model.layers.2.blocks.6.mlp.fc2.bias', 'vit_model.layers.2.blocks.7.attn_mask', 'vit_model.layers.2.blocks.7.norm1.weight', 'vit_model.layers.2.blocks.7.norm1.bias', 'vit_model.layers.2.blocks.7.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.7.attn.relative_position_index', 'vit_model.layers.2.blocks.7.attn.qkv.weight', 'vit_model.layers.2.blocks.7.attn.qkv.bias', 'vit_model.layers.2.blocks.7.attn.proj.weight', 'vit_model.layers.2.blocks.7.attn.proj.bias', 'vit_model.layers.2.blocks.7.norm2.weight', 'vit_model.layers.2.blocks.7.norm2.bias', 'vit_model.layers.2.blocks.7.mlp.fc1.weight', 'vit_model.layers.2.blocks.7.mlp.fc1.bias', 'vit_model.layers.2.blocks.7.mlp.fc2.weight', 'vit_model.layers.2.blocks.7.mlp.fc2.bias', 'vit_model.layers.2.blocks.8.norm1.weight', 'vit_model.layers.2.blocks.8.norm1.bias', 'vit_model.layers.2.blocks.8.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.8.attn.relative_position_index', 'vit_model.layers.2.blocks.8.attn.qkv.weight', 'vit_model.layers.2.blocks.8.attn.qkv.bias', 'vit_model.layers.2.blocks.8.attn.proj.weight', 'vit_model.layers.2.blocks.8.attn.proj.bias', 'vit_model.layers.2.blocks.8.norm2.weight', 'vit_model.layers.2.blocks.8.norm2.bias', 'vit_model.layers.2.blocks.8.mlp.fc1.weight', 'vit_model.layers.2.blocks.8.mlp.fc1.bias', 'vit_model.layers.2.blocks.8.mlp.fc2.weight', 'vit_model.layers.2.blocks.8.mlp.fc2.bias', 'vit_model.layers.2.blocks.9.attn_mask', 'vit_model.layers.2.blocks.9.norm1.weight', 'vit_model.layers.2.blocks.9.norm1.bias', 'vit_model.layers.2.blocks.9.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.9.attn.relative_position_index', 'vit_model.layers.2.blocks.9.attn.qkv.weight', 'vit_model.layers.2.blocks.9.attn.qkv.bias', 'vit_model.layers.2.blocks.9.attn.proj.weight', 'vit_model.layers.2.blocks.9.attn.proj.bias', 'vit_model.layers.2.blocks.9.norm2.weight', 'vit_model.layers.2.blocks.9.norm2.bias', 'vit_model.layers.2.blocks.9.mlp.fc1.weight', 'vit_model.layers.2.blocks.9.mlp.fc1.bias', 'vit_model.layers.2.blocks.9.mlp.fc2.weight', 'vit_model.layers.2.blocks.9.mlp.fc2.bias', 'vit_model.layers.2.blocks.10.norm1.weight', 'vit_model.layers.2.blocks.10.norm1.bias', 'vit_model.layers.2.blocks.10.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.10.attn.relative_position_index', 'vit_model.layers.2.blocks.10.attn.qkv.weight', 'vit_model.layers.2.blocks.10.attn.qkv.bias', 'vit_model.layers.2.blocks.10.attn.proj.weight', 'vit_model.layers.2.blocks.10.attn.proj.bias', 'vit_model.layers.2.blocks.10.norm2.weight', 'vit_model.layers.2.blocks.10.norm2.bias', 'vit_model.layers.2.blocks.10.mlp.fc1.weight', 'vit_model.layers.2.blocks.10.mlp.fc1.bias', 'vit_model.layers.2.blocks.10.mlp.fc2.weight', 'vit_model.layers.2.blocks.10.mlp.fc2.bias', 'vit_model.layers.2.blocks.11.attn_mask', 'vit_model.layers.2.blocks.11.norm1.weight', 'vit_model.layers.2.blocks.11.norm1.bias', 'vit_model.layers.2.blocks.11.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.11.attn.relative_position_index', 'vit_model.layers.2.blocks.11.attn.qkv.weight', 'vit_model.layers.2.blocks.11.attn.qkv.bias', 'vit_model.layers.2.blocks.11.attn.proj.weight', 'vit_model.layers.2.blocks.11.attn.proj.bias', 'vit_model.layers.2.blocks.11.norm2.weight', 'vit_model.layers.2.blocks.11.norm2.bias', 'vit_model.layers.2.blocks.11.mlp.fc1.weight', 'vit_model.layers.2.blocks.11.mlp.fc1.bias', 'vit_model.layers.2.blocks.11.mlp.fc2.weight', 'vit_model.layers.2.blocks.11.mlp.fc2.bias', 'vit_model.layers.2.blocks.12.norm1.weight', 'vit_model.layers.2.blocks.12.norm1.bias', 'vit_model.layers.2.blocks.12.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.12.attn.relative_position_index', 'vit_model.layers.2.blocks.12.attn.qkv.weight', 'vit_model.layers.2.blocks.12.attn.qkv.bias', 'vit_model.layers.2.blocks.12.attn.proj.weight', 'vit_model.layers.2.blocks.12.attn.proj.bias', 'vit_model.layers.2.blocks.12.norm2.weight', 'vit_model.layers.2.blocks.12.norm2.bias', 'vit_model.layers.2.blocks.12.mlp.fc1.weight', 'vit_model.layers.2.blocks.12.mlp.fc1.bias', 'vit_model.layers.2.blocks.12.mlp.fc2.weight', 'vit_model.layers.2.blocks.12.mlp.fc2.bias', 'vit_model.layers.2.blocks.13.attn_mask', 'vit_model.layers.2.blocks.13.norm1.weight', 'vit_model.layers.2.blocks.13.norm1.bias', 'vit_model.layers.2.blocks.13.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.13.attn.relative_position_index', 'vit_model.layers.2.blocks.13.attn.qkv.weight', 'vit_model.layers.2.blocks.13.attn.qkv.bias', 'vit_model.layers.2.blocks.13.attn.proj.weight', 'vit_model.layers.2.blocks.13.attn.proj.bias', 'vit_model.layers.2.blocks.13.norm2.weight', 'vit_model.layers.2.blocks.13.norm2.bias', 'vit_model.layers.2.blocks.13.mlp.fc1.weight', 'vit_model.layers.2.blocks.13.mlp.fc1.bias', 'vit_model.layers.2.blocks.13.mlp.fc2.weight', 'vit_model.layers.2.blocks.13.mlp.fc2.bias', 'vit_model.layers.2.blocks.14.norm1.weight', 'vit_model.layers.2.blocks.14.norm1.bias', 'vit_model.layers.2.blocks.14.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.14.attn.alpha_i2t', 'vit_model.layers.2.blocks.14.attn.relative_position_index', 'vit_model.layers.2.blocks.14.attn.qkv.weight', 'vit_model.layers.2.blocks.14.attn.qkv.bias', 'vit_model.layers.2.blocks.14.attn.proj.weight', 'vit_model.layers.2.blocks.14.attn.proj.bias', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.14.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.14.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.14.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.14.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.14.norm2.weight', 'vit_model.layers.2.blocks.14.norm2.bias', 'vit_model.layers.2.blocks.14.mlp.fc1.weight', 'vit_model.layers.2.blocks.14.mlp.fc1.bias', 'vit_model.layers.2.blocks.14.mlp.fc2.weight', 'vit_model.layers.2.blocks.14.mlp.fc2.bias', 'vit_model.layers.2.blocks.15.attn_mask', 'vit_model.layers.2.blocks.15.norm1.weight', 'vit_model.layers.2.blocks.15.norm1.bias', 'vit_model.layers.2.blocks.15.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.15.attn.alpha_i2t', 'vit_model.layers.2.blocks.15.attn.relative_position_index', 'vit_model.layers.2.blocks.15.attn.qkv.weight', 'vit_model.layers.2.blocks.15.attn.qkv.bias', 'vit_model.layers.2.blocks.15.attn.proj.weight', 'vit_model.layers.2.blocks.15.attn.proj.bias', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.15.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.15.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.15.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.15.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.15.norm2.weight', 'vit_model.layers.2.blocks.15.norm2.bias', 'vit_model.layers.2.blocks.15.mlp.fc1.weight', 'vit_model.layers.2.blocks.15.mlp.fc1.bias', 'vit_model.layers.2.blocks.15.mlp.fc2.weight', 'vit_model.layers.2.blocks.15.mlp.fc2.bias', 'vit_model.layers.2.blocks.16.norm1.weight', 'vit_model.layers.2.blocks.16.norm1.bias', 'vit_model.layers.2.blocks.16.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.16.attn.alpha_i2t', 'vit_model.layers.2.blocks.16.attn.relative_position_index', 'vit_model.layers.2.blocks.16.attn.qkv.weight', 'vit_model.layers.2.blocks.16.attn.qkv.bias', 'vit_model.layers.2.blocks.16.attn.proj.weight', 'vit_model.layers.2.blocks.16.attn.proj.bias', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.16.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.16.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.16.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.16.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.16.norm2.weight', 'vit_model.layers.2.blocks.16.norm2.bias', 'vit_model.layers.2.blocks.16.mlp.fc1.weight', 'vit_model.layers.2.blocks.16.mlp.fc1.bias', 'vit_model.layers.2.blocks.16.mlp.fc2.weight', 'vit_model.layers.2.blocks.16.mlp.fc2.bias', 'vit_model.layers.2.blocks.17.attn_mask', 'vit_model.layers.2.blocks.17.norm1.weight', 'vit_model.layers.2.blocks.17.norm1.bias', 'vit_model.layers.2.blocks.17.attn.relative_position_bias_table', 'vit_model.layers.2.blocks.17.attn.alpha_i2t', 'vit_model.layers.2.blocks.17.attn.relative_position_index', 'vit_model.layers.2.blocks.17.attn.qkv.weight', 'vit_model.layers.2.blocks.17.attn.qkv.bias', 'vit_model.layers.2.blocks.17.attn.proj.weight', 'vit_model.layers.2.blocks.17.attn.proj.bias', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_text_i2t.bias', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.weight', 'vit_model.layers.2.blocks.17.attn.qkv_i2t.bias', 'vit_model.layers.2.blocks.17.attn.proj_i2t.weight', 'vit_model.layers.2.blocks.17.attn.proj_i2t.bias', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.weight', 'vit_model.layers.2.blocks.17.attn.norm_i2t_i.bias', 'vit_model.layers.2.blocks.17.norm2.weight', 'vit_model.layers.2.blocks.17.norm2.bias', 'vit_model.layers.2.blocks.17.mlp.fc1.weight', 'vit_model.layers.2.blocks.17.mlp.fc1.bias', 'vit_model.layers.2.blocks.17.mlp.fc2.weight', 'vit_model.layers.2.blocks.17.mlp.fc2.bias', 'vit_model.layers.2.downsample.reduction.weight', 'vit_model.layers.2.downsample.norm.weight', 'vit_model.layers.2.downsample.norm.bias', 'vit_model.layers.3.blocks.0.norm1.weight', 'vit_model.layers.3.blocks.0.norm1.bias', 'vit_model.layers.3.blocks.0.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.0.attn.alpha_i2t', 'vit_model.layers.3.blocks.0.attn.relative_position_index', 'vit_model.layers.3.blocks.0.attn.qkv.weight', 'vit_model.layers.3.blocks.0.attn.qkv.bias', 'vit_model.layers.3.blocks.0.attn.proj.weight', 'vit_model.layers.3.blocks.0.attn.proj.bias', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.0.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.0.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.0.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.0.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.0.norm2.weight', 'vit_model.layers.3.blocks.0.norm2.bias', 'vit_model.layers.3.blocks.0.mlp.fc1.weight', 'vit_model.layers.3.blocks.0.mlp.fc1.bias', 'vit_model.layers.3.blocks.0.mlp.fc2.weight', 'vit_model.layers.3.blocks.0.mlp.fc2.bias', 'vit_model.layers.3.blocks.1.norm1.weight', 'vit_model.layers.3.blocks.1.norm1.bias', 'vit_model.layers.3.blocks.1.attn.relative_position_bias_table', 'vit_model.layers.3.blocks.1.attn.alpha_i2t', 'vit_model.layers.3.blocks.1.attn.relative_position_index', 'vit_model.layers.3.blocks.1.attn.qkv.weight', 'vit_model.layers.3.blocks.1.attn.qkv.bias', 'vit_model.layers.3.blocks.1.attn.proj.weight', 'vit_model.layers.3.blocks.1.attn.proj.bias', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_text_i2t.bias', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.weight', 'vit_model.layers.3.blocks.1.attn.qkv_i2t.bias', 'vit_model.layers.3.blocks.1.attn.proj_i2t.weight', 'vit_model.layers.3.blocks.1.attn.proj_i2t.bias', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.weight', 'vit_model.layers.3.blocks.1.attn.norm_i2t_i.bias', 'vit_model.layers.3.blocks.1.norm2.weight', 'vit_model.layers.3.blocks.1.norm2.bias', 'vit_model.layers.3.blocks.1.mlp.fc1.weight', 'vit_model.layers.3.blocks.1.mlp.fc1.bias', 'vit_model.layers.3.blocks.1.mlp.fc2.weight', 'vit_model.layers.3.blocks.1.mlp.fc2.bias', 'vit_model.norm.weight', 'vit_model.norm.bias', 'text_transformer.embeddings.position_ids', 'text_transformer.embeddings.word_embeddings.weight', 'text_transformer.embeddings.position_embeddings.weight', 'text_transformer.embeddings.token_type_embeddings.weight', 'text_transformer.embeddings.LayerNorm.weight', 'text_transformer.embeddings.LayerNorm.bias', 'text_transformer.encoder.layer.0.alpha_t2i', 'text_transformer.encoder.layer.0.attention.self.query.weight', 'text_transformer.encoder.layer.0.attention.self.query.bias', 'text_transformer.encoder.layer.0.attention.self.key.weight', 'text_transformer.encoder.layer.0.attention.self.key.bias', 'text_transformer.encoder.layer.0.attention.self.value.weight', 'text_transformer.encoder.layer.0.attention.self.value.bias', 'text_transformer.encoder.layer.0.attention.output.dense.weight', 'text_transformer.encoder.layer.0.attention.output.dense.bias', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.0.intermediate.dense.weight', 'text_transformer.encoder.layer.0.intermediate.dense.bias', 'text_transformer.encoder.layer.0.output.dense.weight', 'text_transformer.encoder.layer.0.output.dense.bias', 'text_transformer.encoder.layer.0.output.LayerNorm.weight', 'text_transformer.encoder.layer.0.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.alpha_t2i', 'text_transformer.encoder.layer.1.attention.self.query.weight', 'text_transformer.encoder.layer.1.attention.self.query.bias', 'text_transformer.encoder.layer.1.attention.self.key.weight', 'text_transformer.encoder.layer.1.attention.self.key.bias', 'text_transformer.encoder.layer.1.attention.self.value.weight', 'text_transformer.encoder.layer.1.attention.self.value.bias', 'text_transformer.encoder.layer.1.attention.output.dense.weight', 'text_transformer.encoder.layer.1.attention.output.dense.bias', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.1.intermediate.dense.weight', 'text_transformer.encoder.layer.1.intermediate.dense.bias', 'text_transformer.encoder.layer.1.output.dense.weight', 'text_transformer.encoder.layer.1.output.dense.bias', 'text_transformer.encoder.layer.1.output.LayerNorm.weight', 'text_transformer.encoder.layer.1.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.alpha_t2i', 'text_transformer.encoder.layer.2.attention.self.query.weight', 'text_transformer.encoder.layer.2.attention.self.query.bias', 'text_transformer.encoder.layer.2.attention.self.key.weight', 'text_transformer.encoder.layer.2.attention.self.key.bias', 'text_transformer.encoder.layer.2.attention.self.value.weight', 'text_transformer.encoder.layer.2.attention.self.value.bias', 'text_transformer.encoder.layer.2.attention.output.dense.weight', 'text_transformer.encoder.layer.2.attention.output.dense.bias', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.2.intermediate.dense.weight', 'text_transformer.encoder.layer.2.intermediate.dense.bias', 'text_transformer.encoder.layer.2.output.dense.weight', 'text_transformer.encoder.layer.2.output.dense.bias', 'text_transformer.encoder.layer.2.output.LayerNorm.weight', 'text_transformer.encoder.layer.2.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.alpha_t2i', 'text_transformer.encoder.layer.3.attention.self.query.weight', 'text_transformer.encoder.layer.3.attention.self.query.bias', 'text_transformer.encoder.layer.3.attention.self.key.weight', 'text_transformer.encoder.layer.3.attention.self.key.bias', 'text_transformer.encoder.layer.3.attention.self.value.weight', 'text_transformer.encoder.layer.3.attention.self.value.bias', 'text_transformer.encoder.layer.3.attention.output.dense.weight', 'text_transformer.encoder.layer.3.attention.output.dense.bias', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.3.intermediate.dense.weight', 'text_transformer.encoder.layer.3.intermediate.dense.bias', 'text_transformer.encoder.layer.3.output.dense.weight', 'text_transformer.encoder.layer.3.output.dense.bias', 'text_transformer.encoder.layer.3.output.LayerNorm.weight', 'text_transformer.encoder.layer.3.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.alpha_t2i', 'text_transformer.encoder.layer.4.attention.self.query.weight', 'text_transformer.encoder.layer.4.attention.self.query.bias', 'text_transformer.encoder.layer.4.attention.self.key.weight', 'text_transformer.encoder.layer.4.attention.self.key.bias', 'text_transformer.encoder.layer.4.attention.self.value.weight', 'text_transformer.encoder.layer.4.attention.self.value.bias', 'text_transformer.encoder.layer.4.attention.output.dense.weight', 'text_transformer.encoder.layer.4.attention.output.dense.bias', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.4.intermediate.dense.weight', 'text_transformer.encoder.layer.4.intermediate.dense.bias', 'text_transformer.encoder.layer.4.output.dense.weight', 'text_transformer.encoder.layer.4.output.dense.bias', 'text_transformer.encoder.layer.4.output.LayerNorm.weight', 'text_transformer.encoder.layer.4.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.alpha_t2i', 'text_transformer.encoder.layer.5.attention.self.query.weight', 'text_transformer.encoder.layer.5.attention.self.query.bias', 'text_transformer.encoder.layer.5.attention.self.key.weight', 'text_transformer.encoder.layer.5.attention.self.key.bias', 'text_transformer.encoder.layer.5.attention.self.value.weight', 'text_transformer.encoder.layer.5.attention.self.value.bias', 'text_transformer.encoder.layer.5.attention.output.dense.weight', 'text_transformer.encoder.layer.5.attention.output.dense.bias', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.5.intermediate.dense.weight', 'text_transformer.encoder.layer.5.intermediate.dense.bias', 'text_transformer.encoder.layer.5.output.dense.weight', 'text_transformer.encoder.layer.5.output.dense.bias', 'text_transformer.encoder.layer.5.output.LayerNorm.weight', 'text_transformer.encoder.layer.5.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.alpha_t2i', 'text_transformer.encoder.layer.6.attention.self.query.weight', 'text_transformer.encoder.layer.6.attention.self.query.bias', 'text_transformer.encoder.layer.6.attention.self.key.weight', 'text_transformer.encoder.layer.6.attention.self.key.bias', 'text_transformer.encoder.layer.6.attention.self.value.weight', 'text_transformer.encoder.layer.6.attention.self.value.bias', 'text_transformer.encoder.layer.6.attention.output.dense.weight', 'text_transformer.encoder.layer.6.attention.output.dense.bias', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.6.intermediate.dense.weight', 'text_transformer.encoder.layer.6.intermediate.dense.bias', 'text_transformer.encoder.layer.6.output.dense.weight', 'text_transformer.encoder.layer.6.output.dense.bias', 'text_transformer.encoder.layer.6.output.LayerNorm.weight', 'text_transformer.encoder.layer.6.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.alpha_t2i', 'text_transformer.encoder.layer.7.attention.self.query.weight', 'text_transformer.encoder.layer.7.attention.self.query.bias', 'text_transformer.encoder.layer.7.attention.self.key.weight', 'text_transformer.encoder.layer.7.attention.self.key.bias', 'text_transformer.encoder.layer.7.attention.self.value.weight', 'text_transformer.encoder.layer.7.attention.self.value.bias', 'text_transformer.encoder.layer.7.attention.output.dense.weight', 'text_transformer.encoder.layer.7.attention.output.dense.bias', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.7.intermediate.dense.weight', 'text_transformer.encoder.layer.7.intermediate.dense.bias', 'text_transformer.encoder.layer.7.output.dense.weight', 'text_transformer.encoder.layer.7.output.dense.bias', 'text_transformer.encoder.layer.7.output.LayerNorm.weight', 'text_transformer.encoder.layer.7.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.alpha_t2i', 'text_transformer.encoder.layer.8.attention.self.query.weight', 'text_transformer.encoder.layer.8.attention.self.query.bias', 'text_transformer.encoder.layer.8.attention.self.key.weight', 'text_transformer.encoder.layer.8.attention.self.key.bias', 'text_transformer.encoder.layer.8.attention.self.value.weight', 'text_transformer.encoder.layer.8.attention.self.value.bias', 'text_transformer.encoder.layer.8.attention.output.dense.weight', 'text_transformer.encoder.layer.8.attention.output.dense.bias', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.8.intermediate.dense.weight', 'text_transformer.encoder.layer.8.intermediate.dense.bias', 'text_transformer.encoder.layer.8.output.dense.weight', 'text_transformer.encoder.layer.8.output.dense.bias', 'text_transformer.encoder.layer.8.output.LayerNorm.weight', 'text_transformer.encoder.layer.8.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.alpha_t2i', 'text_transformer.encoder.layer.9.attention.self.query.weight', 'text_transformer.encoder.layer.9.attention.self.query.bias', 'text_transformer.encoder.layer.9.attention.self.key.weight', 'text_transformer.encoder.layer.9.attention.self.key.bias', 'text_transformer.encoder.layer.9.attention.self.value.weight', 'text_transformer.encoder.layer.9.attention.self.value.bias', 'text_transformer.encoder.layer.9.attention.output.dense.weight', 'text_transformer.encoder.layer.9.attention.output.dense.bias', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.9.intermediate.dense.weight', 'text_transformer.encoder.layer.9.intermediate.dense.bias', 'text_transformer.encoder.layer.9.output.dense.weight', 'text_transformer.encoder.layer.9.output.dense.bias', 'text_transformer.encoder.layer.9.output.LayerNorm.weight', 'text_transformer.encoder.layer.9.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.alpha_t2i', 'text_transformer.encoder.layer.10.attention.self.query.weight', 'text_transformer.encoder.layer.10.attention.self.query.bias', 'text_transformer.encoder.layer.10.attention.self.key.weight', 'text_transformer.encoder.layer.10.attention.self.key.bias', 'text_transformer.encoder.layer.10.attention.self.value.weight', 'text_transformer.encoder.layer.10.attention.self.value.bias', 'text_transformer.encoder.layer.10.attention.output.dense.weight', 'text_transformer.encoder.layer.10.attention.output.dense.bias', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.10.intermediate.dense.weight', 'text_transformer.encoder.layer.10.intermediate.dense.bias', 'text_transformer.encoder.layer.10.output.dense.weight', 'text_transformer.encoder.layer.10.output.dense.bias', 'text_transformer.encoder.layer.10.output.LayerNorm.weight', 'text_transformer.encoder.layer.10.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.alpha_t2i', 'text_transformer.encoder.layer.11.attention.self.query.weight', 'text_transformer.encoder.layer.11.attention.self.query.bias', 'text_transformer.encoder.layer.11.attention.self.key.weight', 'text_transformer.encoder.layer.11.attention.self.key.bias', 'text_transformer.encoder.layer.11.attention.self.value.weight', 'text_transformer.encoder.layer.11.attention.self.value.bias', 'text_transformer.encoder.layer.11.attention.output.dense.weight', 'text_transformer.encoder.layer.11.attention.output.dense.bias', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.attention.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.query.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.key.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.self.value.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.dense.bias', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'text_transformer.encoder.layer.11.intermediate.dense.weight', 'text_transformer.encoder.layer.11.intermediate.dense.bias', 'text_transformer.encoder.layer.11.output.dense.weight', 'text_transformer.encoder.layer.11.output.dense.bias', 'text_transformer.encoder.layer.11.output.LayerNorm.weight', 'text_transformer.encoder.layer.11.output.LayerNorm.bias', 'text_transformer.pooler.dense.weight', 'text_transformer.pooler.dense.bias', 'cross_modal_image_pooler.dense.weight', 'cross_modal_image_pooler.dense.bias', 'cross_modal_text_pooler.dense.weight', 'cross_modal_text_pooler.dense.bias', 'cross_modal_image_pooler_itc.dense.weight', 'cross_modal_image_pooler_itc.dense.bias', 'cross_modal_text_pooler_itc.dense.weight', 'cross_modal_text_pooler_itc.dense.bias', 'vqa_classifier.model.0.weight', 'vqa_classifier.model.0.bias', 'vqa_classifier.model.1.weight', 'vqa_classifier.model.1.bias', 'vqa_classifier.model.3.weight', 'vqa_classifier.model.3.bias'])
gr016:3744010:3744010 [0] NCCL INFO Bootstrap : Using ibs1:10.0.3.161<0>
gr016:3744010:3744010 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
gr016:3744010:3744010 [0] NCCL INFO cudaDriverVersion 12020
NCCL version 2.15.5+cuda11.8
Sanity Checking: 0it [00:00, ?it/s]gr016:3744233:3744233 [2] NCCL INFO cudaDriverVersion 12020
gr016:3744233:3744233 [2] NCCL INFO Bootstrap : Using ibs1:10.0.3.161<0>
gr016:3744233:3744233 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
gr016:3744233:3744415 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ibs1:10.0.3.161<0>
gr016:3744233:3744415 [2] NCCL INFO Using network IB
gr016:3744233:3744415 [2] NCCL INFO Setting affinity for GPU 2 to 03000000
gr016:3744233:3744415 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
gr016:3744233:3744415 [2] NCCL INFO Channel 00 : 2[86000] -> 3[d8000] via SHM/direct/direct
gr016:3744233:3744415 [2] NCCL INFO Channel 01 : 2[86000] -> 3[d8000] via SHM/direct/direct
gr016:3744233:3744415 [2] NCCL INFO Connected all rings
gr016:3744233:3744415 [2] NCCL INFO Channel 00 : 2[86000] -> 1[2f000] via SHM/direct/direct
gr016:3744233:3744415 [2] NCCL INFO Channel 01 : 2[86000] -> 1[2f000] via SHM/direct/direct
gr016:3744233:3744415 [2] NCCL INFO Connected all trees
gr016:3744233:3744415 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gr016:3744233:3744415 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
gr016:3744233:3744415 [2] NCCL INFO comm 0x7f117720 rank 2 nranks 4 cudaDev 2 busId 86000 - Init COMPLETE
gr016:3744269:3744269 [3] NCCL INFO cudaDriverVersion 12020
gr016:3744269:3744269 [3] NCCL INFO Bootstrap : Using ibs1:10.0.3.161<0>
gr016:3744269:3744269 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
gr016:3744269:3744417 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ibs1:10.0.3.161<0>
gr016:3744269:3744417 [3] NCCL INFO Using network IB
gr016:3744269:3744417 [3] NCCL INFO Setting affinity for GPU 3 to 03000000
gr016:3744269:3744417 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
gr016:3744269:3744417 [3] NCCL INFO Channel 00 : 3[d8000] -> 0[6000] via SHM/direct/direct
gr016:3744269:3744417 [3] NCCL INFO Channel 01 : 3[d8000] -> 0[6000] via SHM/direct/direct
gr016:3744269:3744417 [3] NCCL INFO Connected all rings
gr016:3744269:3744417 [3] NCCL INFO Channel 00 : 3[d8000] -> 2[86000] via SHM/direct/direct
gr016:3744269:3744417 [3] NCCL INFO Channel 01 : 3[d8000] -> 2[86000] via SHM/direct/direct
gr016:3744269:3744417 [3] NCCL INFO Connected all trees
gr016:3744269:3744417 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gr016:3744269:3744417 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
gr016:3744269:3744417 [3] NCCL INFO comm 0x835ba330 rank 3 nranks 4 cudaDev 3 busId d8000 - Init COMPLETE
gr016:3744230:3744230 [1] NCCL INFO cudaDriverVersion 12020
gr016:3744230:3744230 [1] NCCL INFO Bootstrap : Using ibs1:10.0.3.161<0>
gr016:3744230:3744230 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
gr016:3744230:3744416 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ibs1:10.0.3.161<0>
gr016:3744230:3744416 [1] NCCL INFO Using network IB
gr016:3744230:3744416 [1] NCCL INFO Setting affinity for GPU 1 to 03
gr016:3744230:3744416 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
gr016:3744230:3744416 [1] NCCL INFO Channel 00 : 1[2f000] -> 2[86000] via SHM/direct/direct
gr016:3744230:3744416 [1] NCCL INFO Channel 01 : 1[2f000] -> 2[86000] via SHM/direct/direct
gr016:3744230:3744416 [1] NCCL INFO Connected all rings
gr016:3744230:3744416 [1] NCCL INFO Channel 00 : 1[2f000] -> 0[6000] via SHM/direct/direct
gr016:3744230:3744416 [1] NCCL INFO Channel 01 : 1[2f000] -> 0[6000] via SHM/direct/direct
gr016:3744230:3744416 [1] NCCL INFO Connected all trees
gr016:3744230:3744416 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gr016:3744230:3744416 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
gr016:3744230:3744416 [1] NCCL INFO comm 0x82a82260 rank 1 nranks 4 cudaDev 1 busId 2f000 - Init COMPLETE
Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]gr016:3744010:3744414 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ibs1:10.0.3.161<0>
gr016:3744010:3744414 [0] NCCL INFO Using network IB
gr016:3744010:3744414 [0] NCCL INFO Setting affinity for GPU 0 to 03
gr016:3744010:3744414 [0] NCCL INFO Channel 00/02 :    0   1   2   3
gr016:3744010:3744414 [0] NCCL INFO Channel 01/02 :    0   1   2   3
gr016:3744010:3744414 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
gr016:3744010:3744414 [0] NCCL INFO Channel 00 : 0[6000] -> 1[2f000] via SHM/direct/direct
gr016:3744010:3744414 [0] NCCL INFO Channel 01 : 0[6000] -> 1[2f000] via SHM/direct/direct
gr016:3744010:3744414 [0] NCCL INFO Connected all rings
gr016:3744010:3744414 [0] NCCL INFO Connected all trees
gr016:3744010:3744414 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gr016:3744010:3744414 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
gr016:3744010:3744414 [0] NCCL INFO comm 0x84c33210 rank 0 nranks 4 cudaDev 0 busId 6000 - Init COMPLETE
gr016:3744269:3744425 [3] NCCL INFO [Service thread] Connection closed by localRank 3
gr016:3744269:3744269 [3] NCCL INFO comm 0x835ba330 rank 3 nranks 4 cudaDev 3 busId d8000 - Abort COMPLETE
gr016:3744230:3744424 [1] NCCL INFO [Service thread] Connection closed by localRank 1
gr016:3744233:3744422 [2] NCCL INFO [Service thread] Connection closed by localRank 2
gr016:3744230:3744230 [1] NCCL INFO comm 0x82a82260 rank 1 nranks 4 cudaDev 1 busId 2f000 - Abort COMPLETE
gr016:3744233:3744233 [2] NCCL INFO comm 0x7f117720 rank 2 nranks 4 cudaDev 2 busId 86000 - Abort COMPLETE
                                                                   gr016:3744010:3744423 [0] NCCL INFO [Service thread] Connection closed by localRank 0
gr016:3744010:3744010 [0] NCCL INFO comm 0x84c33210 rank 0 nranks 4 cudaDev 0 busId 6000 - Abort COMPLETE
