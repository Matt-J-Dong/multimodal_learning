.env: line 1: WANDB_API_KEY: command not found
wandb: ERROR Find detailed error logs at: /scratch/mjd9571/multimodal_learning/vqa_nlvr/wandb/debug-cli.mjd9571.log
Error: api_key not configured (no-tty). call wandb login [your_api_key]
WARNING - root - Changed type of config entry "max_steps" from int to NoneType
WARNING - FIBER - No observers have been added to this run
INFO - FIBER - Running command 'main'
INFO - FIBER - Started
Global seed set to 3
/home/mjd9571/.local/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.0.alpha_t2i', 'roberta.encoder.layer.1.alpha_t2i', 'roberta.encoder.layer.10.alpha_t2i', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.11.alpha_t2i', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.2.alpha_t2i', 'roberta.encoder.layer.3.alpha_t2i', 'roberta.encoder.layer.4.alpha_t2i', 'roberta.encoder.layer.5.alpha_t2i', 'roberta.encoder.layer.6.alpha_t2i', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.7.alpha_t2i', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.8.alpha_t2i', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.9.alpha_t2i', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.value.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/mjd9571/.local/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has
                not been set for this class (VQAScore). The property determines if `update` by
                default needs access to the full metric state. If this is not the case, significant speedups can be
                achieved and we recommend setting this to `False`.
                We provide an checking function
                `from torchmetrics.utilities import check_forward_full_state_property`
                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,
                default for now) or if `full_state_update=False` can be used safely.
                
  warnings.warn(*args, **kwargs)
/home/mjd9571/.local/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has
                not been set for this class (Scalar). The property determines if `update` by
                default needs access to the full metric state. If this is not the case, significant speedups can be
                achieved and we recommend setting this to `False`.
                We provide an checking function
                `from torchmetrics.utilities import check_forward_full_state_property`
                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,
                default for now) or if `full_state_update=False` can be used safely.
                
  warnings.warn(*args, **kwargs)
wandb: Currently logged in as: matt-j-dong (project-sprite). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.3
wandb: Run data is saved locally in ./wandb/run-20241003_154634-5alfj3pi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run intra_modality_vqa-0.0001
wandb: ‚≠êÔ∏è View project at https://wandb.ai/project-sprite/multimodal_vqa
wandb: üöÄ View run at https://wandb.ai/project-sprite/multimodal_vqa/runs/5alfj3pi
/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:161: UserWarning: You passed `deterministic=True` and `benchmark=True`. Note that PyTorch ignores torch.backends.cudnn.deterministic=True when torch.backends.cudnn.benchmark=True.
  rank_zero_warn(
/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.
  rank_zero_deprecation(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
WARNING - root - Changed type of config entry "max_steps" from int to NoneType
WARNING - FIBER - No observers have been added to this run
INFO - FIBER - Running command 'main'
INFO - FIBER - Started
Global seed set to 3
/home/mjd9571/.local/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
WARNING - root - Changed type of config entry "max_steps" from int to NoneType
WARNING - FIBER - No observers have been added to this run
INFO - FIBER - Running command 'main'
INFO - FIBER - Started
Global seed set to 3
/home/mjd9571/.local/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Global seed set to 3
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.0.alpha_t2i', 'roberta.encoder.layer.1.alpha_t2i', 'roberta.encoder.layer.10.alpha_t2i', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.11.alpha_t2i', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.2.alpha_t2i', 'roberta.encoder.layer.3.alpha_t2i', 'roberta.encoder.layer.4.alpha_t2i', 'roberta.encoder.layer.5.alpha_t2i', 'roberta.encoder.layer.6.alpha_t2i', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.7.alpha_t2i', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.8.alpha_t2i', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.9.alpha_t2i', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.value.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
WARNING - root - Changed type of config entry "max_steps" from int to NoneType
WARNING - FIBER - No observers have been added to this run
INFO - FIBER - Running command 'main'
INFO - FIBER - Started
Global seed set to 3
/home/mjd9571/.local/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.0.alpha_t2i', 'roberta.encoder.layer.1.alpha_t2i', 'roberta.encoder.layer.10.alpha_t2i', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.11.alpha_t2i', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.2.alpha_t2i', 'roberta.encoder.layer.3.alpha_t2i', 'roberta.encoder.layer.4.alpha_t2i', 'roberta.encoder.layer.5.alpha_t2i', 'roberta.encoder.layer.6.alpha_t2i', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.7.alpha_t2i', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.8.alpha_t2i', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.9.alpha_t2i', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.value.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Global seed set to 3
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:1 to store for rank: 1
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.0.alpha_t2i', 'roberta.encoder.layer.1.alpha_t2i', 'roberta.encoder.layer.10.alpha_t2i', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.10.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.10.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.10.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.11.alpha_t2i', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.11.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.11.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.11.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.2.alpha_t2i', 'roberta.encoder.layer.3.alpha_t2i', 'roberta.encoder.layer.4.alpha_t2i', 'roberta.encoder.layer.5.alpha_t2i', 'roberta.encoder.layer.6.alpha_t2i', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.6.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.6.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.6.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.7.alpha_t2i', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.7.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.7.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.7.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.8.alpha_t2i', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.8.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.8.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.8.crossattention_t2i.self.value.weight', 'roberta.encoder.layer.9.alpha_t2i', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.bias', 'roberta.encoder.layer.9.crossattention_t2i.output.dense.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.key.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.key.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.query.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.query.weight', 'roberta.encoder.layer.9.crossattention_t2i.self.value.bias', 'roberta.encoder.layer.9.crossattention_t2i.self.value.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Global seed set to 3
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:1 to store for rank: 2
Global seed set to 3
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:1 to store for rank: 3
INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:1 to store for rank: 0
INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO - torch.distributed.distributed_c10d - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO - torch.distributed.distributed_c10d - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/datasets/vqav2_dataset.py:16: FutureWarning: promote has been superseded by promote_options='default'.
  super().__init__(
/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/datasets/vqav2_dataset.py:16: FutureWarning: promote has been superseded by promote_options='default'.
  super().__init__(
/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/datasets/vqav2_dataset.py:16: FutureWarning: promote has been superseded by promote_options='default'.
  super().__init__(
/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/datasets/vqav2_dataset.py:16: FutureWarning: promote has been superseded by promote_options='default'.
  super().__init__(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

   | Name                            | Type                    | Params
-----------------------------------------------------------------------------
0  | cross_modal_text_transform      | Linear                  | 590 K 
1  | cross_modal_image_transform     | Linear                  | 787 K 
2  | cross_modal_text_transform_itc  | Linear                  | 590 K 
3  | cross_modal_image_transform_itc | Linear                  | 787 K 
4  | vit_model                       | SwinTransformer         | 99.7 M
5  | avgpool                         | AdaptiveAvgPool1d       | 0     
6  | text_transformer                | RobertaModel            | 138 M 
7  | cross_modal_image_pooler        | Pooler                  | 590 K 
8  | cross_modal_text_pooler         | Pooler                  | 590 K 
9  | cross_modal_image_pooler_itc    | Pooler                  | 590 K 
10 | cross_modal_text_pooler_itc     | Pooler                  | 590 K 
11 | vqa_classifier                  | IntraModalityClassifier | 12.0 M
12 | train_vqa_score                 | VQAScore                | 0     
13 | train_vqa_loss                  | Scalar                  | 0     
14 | val_vqa_score                   | VQAScore                | 0     
15 | val_vqa_loss                    | Scalar                  | 0     
-----------------------------------------------------------------------------
12.0 M    Trainable params
242 M     Non-trainable params
254 M     Total params
1,019.582 Total estimated model params size (MB)
/home/mjd9571/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/mjd9571/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/mjd9571/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/mjd9571/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/mjd9571/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/mjd9571/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/mjd9571/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/mjd9571/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:1101: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
ERROR - FIBER - Failed after 0:00:43!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/vqa_intra_run.py", line 80, in main
    trainer.fit(model, datamodule=dm)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _run_train
    self._run_sanity_check()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1343, in _run_sanity_check
    val_loop.run()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 155, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 143, in advance
    output = self._evaluation_step(**kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 240, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 358, in validation_step
    return self.model(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py", line 90, in forward
    return self.module.validation_step(*inputs, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 493, in validation_step
    output = self(batch)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 467, in forward
    ret.update(objectives.compute_vqa(self, batch))
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/objectives.py", line 86, in compute_vqa
    "image": infer["image"],
UnboundLocalError: local variable 'infer' referenced before assignment

ERROR - FIBER - Failed after 0:00:52!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/vqa_intra_run.py", line 80, in main
    trainer.fit(model, datamodule=dm)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _run_train
    self._run_sanity_check()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1343, in _run_sanity_check
    val_loop.run()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 155, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 143, in advance
    output = self._evaluation_step(**kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 240, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 358, in validation_step
    return self.model(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py", line 90, in forward
    return self.module.validation_step(*inputs, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 493, in validation_step
    output = self(batch)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 467, in forward
    ret.update(objectives.compute_vqa(self, batch))
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/objectives.py", line 86, in compute_vqa
    "image": infer["image"],
UnboundLocalError: local variable 'infer' referenced before assignment

ERROR - FIBER - Failed after 0:01:29!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/vqa_intra_run.py", line 80, in main
    trainer.fit(model, datamodule=dm)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 648, in _call_and_handle_interrupt
    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 93, in launch
    return function(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _run_train
    self._run_sanity_check()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1343, in _run_sanity_check
    val_loop.run()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 155, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 143, in advance
    output = self._evaluation_step(**kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 240, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 358, in validation_step
    return self.model(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py", line 90, in forward
    return self.module.validation_step(*inputs, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 493, in validation_step
    output = self(batch)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 467, in forward
    ret.update(objectives.compute_vqa(self, batch))
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/objectives.py", line 86, in compute_vqa
    "image": infer["image"],
UnboundLocalError: local variable 'infer' referenced before assignment

ERROR - FIBER - Failed after 0:00:49!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/vqa_intra_run.py", line 80, in main
    trainer.fit(model, datamodule=dm)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _run_train
    self._run_sanity_check()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1343, in _run_sanity_check
    val_loop.run()
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 155, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 143, in advance
    output = self._evaluation_step(**kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 240, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 358, in validation_step
    return self.model(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py", line 90, in forward
    return self.module.validation_step(*inputs, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 493, in validation_step
    output = self(batch)
  File "/home/mjd9571/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/fiber_module.py", line 467, in forward
    ret.update(objectives.compute_vqa(self, batch))
  File "/scratch/mjd9571/multimodal_learning/vqa_nlvr/fiber/modules/objectives.py", line 86, in compute_vqa
    "image": infer["image"],
UnboundLocalError: local variable 'infer' referenced before assignment

wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.017 MB of 0.036 MB uploadedwandb: / 0.036 MB of 0.036 MB uploadedwandb: üöÄ View run intra_modality_vqa-0.0001 at: https://wandb.ai/project-sprite/multimodal_vqa/runs/5alfj3pi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/project-sprite/multimodal_vqa
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241003_154634-5alfj3pi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
WARNING - urllib3.connectionpool - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(FileNotFoundError(2, 'No such file or directory'))': /api/4504800232407040/envelope/
WARNING - urllib3.connectionpool - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(FileNotFoundError(2, 'No such file or directory'))': /api/4504800232407040/envelope/
WARNING - urllib3.connectionpool - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(FileNotFoundError(2, 'No such file or directory'))': /api/4504800232407040/envelope/
WARNING - urllib3.connectionpool - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(FileNotFoundError(2, 'No such file or directory'))': /api/4504800232407040/envelope/
WARNING - urllib3.connectionpool - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(FileNotFoundError(2, 'No such file or directory'))': /api/4504800232407040/envelope/
WARNING - urllib3.connectionpool - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(FileNotFoundError(2, 'No such file or directory'))': /api/4504800232407040/envelope/
